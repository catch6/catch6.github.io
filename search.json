[{"title":"设计模式之桥接模式","url":"/posts/bd19161c.html","content":"\n在 GoF 的《设计模式》一书中，桥接模式被定义为：“将抽象和实现解耦，让它们可以独立变化。”定义中的“抽象”，指的并非“抽象类”或“接口”，而是被抽象出来的一套“类库”，它只包含骨架代码，真正的业务逻辑需要委派给定义中的“实现”来完成。而定义中的“实现”，也并非“接口的实现类”，而是一套独立的“类库”。\n\n## 应用场景\n\n系统可能有多个维度，每个维度都有可能变化。\n\n## 类图\n\n![类图](https://cdn.wenzuo.net/assets/202201251147699.png)\n\n将 Color 类组合在 Shape 中来将形状和颜色解耦，各自维护各自的变化，这里体现了组合优于继承的设计原则。\n\n桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。\n\n## 代码实现\n\nColor\n\n```java\npublic abstract class Color {\n\n    public abstract void paint(String shape);\n\n}\n```\n\nRed\n\n```java\npublic class Red extends Color {\n\n    @Override\n    public void paint(String shape) {\n        System.out.println(\"红色的\" + shape);\n    }\n\n}\n```\n\nGreen\n\n```java\npublic class Green extends Color {\n\n    @Override\n    public void paint(String shape) {\n        System.out.println(\"绿色的\" + shape);\n    }\n\n}\n```\n\nShape\n\n```java\npublic abstract class Shape {\n\n    protected Color color;\n\n    public void setColor(Color color) {\n        this.color = color;\n    }\n\n    public abstract void draw();\n\n}\n```\n\nCircle\n\n```java\npublic class Circle extends Shape {\n\n    @Override\n    public void draw() {\n        color.paint(\"圆形\");\n    }\n\n}\n```\n\nSquare\n\n```java\npublic class Square extends Shape {\n\n    @Override\n    public void draw() {\n        color.paint(\"正方形\");\n    }\n\n}\n```\n\nMain\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        Shape shape;\n        Color color;\n\n        color = new Red();\n        shape = new Circle();\n        shape.setColor(color);\n        shape.draw();\n\n        color = new Green();\n        shape = new Square();\n        shape.setColor(color);\n        shape.draw();\n    }\n\n}\n```\n\n至此，我们已经完成了桥接模式的学习。桥接模式在实际项目中并不常用，这里我们了解认识即可。\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之代理模式","url":"/posts/907a70d0.html","content":"\n> 代理模式是一种结构型设计模式。结构型模式主要总结了一些类或对象组合在一起的经典结构，这些经典的结构可以解决特定应用场景的问题。结构型模式包括：代理模式、桥接模式、装饰器模式、适配器模式、门面模式、组合模式、享元模式。\n\n## 代理模式的应用场景\n\n- 业务系统的非功能性需求开发。比如：监控、统计、鉴权、限流、事务、幂等、日志。我们将这些附加功能与业务功能解耦，放到代理类中统一处理，让程序员只需要关注业务方面的开发。\n- RPC、缓存中应用。RPC 框架也可以看作一种代理模式；假设我们要开发一个接口请求的缓存功能，对于某些接口请求，如果入参相同，在设定的过期时间内，直接返回缓存结果，而不用重新进行逻辑处理。\n\n代理模式分为静态代理和动态代理。静态代理的代理对象，在程序编译时已经写好 Java 文件了，直接 new 一个代理对象即可。动态代理产生代理对象的时机是运行时动态生成，它没有 Java 源文件，直接生成字节码文件实例化代理对象。\n\n静态代理的实现有两种：通过接口和通过继承。\n\n## 静态代理 - 通过接口方式\n\n### 类图\n\n![通过接口方式的类图](https://cdn.wenzuo.net/assets/202201241513198.png)\n\n### 代码实现\n\n#### UserService\n\n```java\npublic interface UserService {\n\n    public Boolean login(String username, String password);\n\n}\n```\n\n#### UserServiceImpl\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    @Override\n    public Boolean login(String username, String password) {\n        return \"admin\".equals(username) && \"admin\".equals(password);\n    }\n\n}\n```\n\n#### UserServiceProxy\n\n```java\npublic class UserServiceProxy implements UserService {\n\n    private final UserService userService;\n\n    public UserServiceProxy(UserService userService) {\n        this.userService = userService;\n    }\n\n    @Override\n    public Boolean login(String username, String password) {\n        long t1 = System.nanoTime();\n        System.out.println(\"start login\");\n        Boolean result = userService.login(username, password);\n        System.out.println(\"end login\");\n        long t2 = System.nanoTime();\n        System.out.println(\"time: \" + (t2 - t1) + \"ns\");\n        return result;\n    }\n\n}\n```\n\n#### Main\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        UserService userService = new UserServiceProxy(new UserServiceImpl());\n        Boolean result = userService.login(\"admin\", \"admin\");\n        System.out.println(\"result: \" + result);\n    }\n\n}\n```\n\n## 静态代理 - 通过继承方式\n\n### 类图\n\n![通过继承方式的类图](https://cdn.wenzuo.net/assets/202201241514975.png)\n\n### 代码实现\n\n#### UserService\n\n```java\npublic interface UserService {\n\n    public Boolean login(String username, String password);\n\n}\n```\n\n#### UserServiceImpl\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    @Override\n    public Boolean login(String username, String password) {\n        return \"admin\".equals(username) && \"admin\".equals(password);\n    }\n\n}\n```\n\n#### UserServiceProxy\n\n```java\npublic class UserServiceProxy extends UserServiceImpl {\n\n    @Override\n    public Boolean login(String username, String password) {\n        long t1 = System.nanoTime();\n        System.out.println(\"start login\");\n        Boolean result = super.login(username, password);\n        System.out.println(\"end login\");\n        long t2 = System.nanoTime();\n        System.out.println(\"time: \" + (t2 - t1) + \"ns\");\n        return result;\n    }\n\n}\n```\n\n#### Main\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        UserService userService = new UserServiceProxy();\n        Boolean result = userService.login(\"admin\", \"admin\");\n        System.out.println(\"result: \" + result);\n    }\n\n}\n```\n\n## 动态代理\n\n上面的代码实现有两个问题：\n\n1. 我们需要在代理类中，将原始类中的所有的方法，都重新实现一遍，并且为每个方法都附加相似的代码逻辑。\n2. 如果要添加的附加功能的类有不止一个，我们需要针对每个类都创建一个代理类。\n\n这时我们就需要用到**动态代理**（Dynamic Proxy），就是我们不事先为每个原始类编写代理类，而是在运行的时候，动态地创建原始类对应的代理类，然后在系统中用代理类替换掉原始类。\n\n### 如何实现动态代理呢？\n\nJava 语言本身就已经提供了动态代理的语法（实际上，动态代理底层依赖的就是 Java 的反射语法）。\n\n### 类图\n\n![动态代理类图](https://cdn.wenzuo.net/assets/202201241619846.png)\n\n### UserService\n\n```java\npublic interface UserService {\n\n    public Boolean login(String username, String password);\n\n}\n```\n\n### UserServiceImpl\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    @Override\n    public Boolean login(String username, String password) {\n        return \"admin\".equals(username) && \"admin\".equals(password);\n    }\n\n}\n```\n\n### DynamicProxyHandler\n\n```java\npublic class DynamicProxyHandler implements InvocationHandler {\n\n    private Object target;\n\n    public DynamicProxyHandler(Object target) {\n        this.target = target;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        long t1 = System.nanoTime();\n        System.out.println(\"start \" + target.getClass().getName() + \":\" + method.getName());\n        Object result = method.invoke(target, args);\n        System.out.println(\"end \" + target.getClass().getName() + \":\" + method.getName());\n        long t2 = System.nanoTime();\n        System.out.println(\"time: \" + (t2 - t1) + \"ns\");\n        return result;\n    }\n\n}\n```\n\n### DynamicProxy\n\n```java\npublic class DynamicProxy {\n\n    public Object createProxy(Object target) {\n        ClassLoader classLoader = target.getClass().getClassLoader();\n        Class<?>[] interfaces = target.getClass().getInterfaces();\n        DynamicProxyHandler handler = new DynamicProxyHandler(target);\n        return Proxy.newProxyInstance(classLoader, interfaces, handler);\n    }\n\n}\n```\n\n### Main\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        DynamicProxy proxy = new DynamicProxy();\n        UserService userService = (UserService) proxy.createProxy(new UserServiceImpl());\n        Boolean result = userService.login(\"admin\", \"admin\");\n        System.out.println(\"result: \" + result);\n    }\n\n}\n```\n\n至此，我们已经实现了基于 JDK 的动态代理，JDK 动态代理要求要代理的类必须实现接口，如果类没有实现接口，那么你可以尝试 `CGLIB`，它不是 JDK 自带的，而是第三方类库，感兴趣可以详细了解。\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之原型模式","url":"/posts/7a86e223.html","content":"\n## 使用场景\n\n如果 **对象的创建成本比较大**，而 **同一个类的不同对象之间差别不大**（大部分字段都相同），在这种情况下，我们可以利用对已有对象（原型）进行复制（或者叫拷贝）的方式来创建新对象，以达到节省创建时间的目的。\n\n## 何为“对象的创建成本比较大”？\n\n如果对象中的数据需要经过复杂的计算才能得到（比如排序、计算哈希值），或者需要从 RPC、网络、数据库、文件系统等非常慢速的 IO 中读取，这种情况下，我们就可以利用原型模式，从其他已有对象中直接拷贝得到，而不用每次在创建新对象的时候，都重复执行这些耗时的操作。\n\n## 原型模式的实现方式：深拷贝和浅拷贝\n\n要使用原型模式，我们就需要对对象进行拷贝，这里我们要先了解下深拷贝和浅拷贝。\n\n浅拷贝和深拷贝的区别在于，浅拷贝只会复制数据的内存地址，而深拷贝会复制数据本身。因此，浅拷贝与原始对象共享数据对象，原始对象如果修改了数据值，拷贝的对象也会变为新的值；而深拷贝得到的是一份完完全全独立的对象，不会受原对象影响。\n\n在 Java 语言中，Object 类的 clone() 方法执行的就是我们刚刚说的浅拷贝。它只会拷贝对象中的基本数据类型的数据（比如，int、long），以及引用对象的内存地址，不会递归地拷贝引用对象本身。\n\n## 那如何实现深拷贝呢？\n\n- 递归拷贝对象、对象的引用对象以及引用对象的引用对象……直到要拷贝的对象只包含基本数据类型数据，没有引用对象为止。\n- 先将对象序列化，然后再反序列化成新的对象。\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之建造者模式","url":"/posts/722e57af.html","content":"\n## 使用场景\n\n- 对象的构建有很多必填参数，如果使用构造函数会导致参数列表过长难以使用\n- 构造参数之间有依赖关系，比如设置了 minAge 就必须设置 maxAge，且 minAge 小于等于 maxAge\n- 类的属性一旦被创建就不可变（不暴力 set()方法）\n\n## 类图\n\n![](https://cdn.wenzuo.net/assets/202201221542175.png)\n\nPerson 类包含了一个内部类 Builder，负责对外暴露设置属性的方法，这些方法可以包含校验和初始化规则，属性之前的依赖规则可以放到最终调用的 build()方法中校验\n\n## 代码实现\n\n```java\npublic class Person {\n\n    private Long id;\n    private String name;\n    private Integer minAge;\n    private Integer maxAge;\n\n    private Person() {\n    }\n\n    public static class Builder {\n\n        private Person person = new Person();\n\n        public Builder id(Long id) {\n            person.id = id;\n            return this;\n        }\n\n        public Builder name(String name) {\n            person.name = name;\n            return this;\n        }\n\n        public Builder minAge(Integer minAge) {\n            person.minAge = minAge;\n            return this;\n        }\n\n        public Builder maxAge(Integer maxAge) {\n            person.maxAge = maxAge;\n            return this;\n        }\n\n        public Person build() {\n            if (person.minAge != null && person.maxAge != null) {\n                if (person.minAge < 0) {\n                    throw new IllegalArgumentException(\"minAge必须大于等于0\");\n                }\n                if (person.maxAge <= person.minAge) {\n                    throw new IllegalArgumentException(\"maxAge必须大于等于minAge\");\n                }\n            } else if ((person.minAge == null && person.maxAge != null) ||\n                    (person.minAge != null && person.maxAge == null)) {\n                throw new IllegalArgumentException(\"minAge和maxAge必须同时设置\");\n            }\n            return person;\n        }\n\n    }\n\n}\n```\n\n## 与工厂模式有何区别？\n\n- 工厂模式是用来创建不同但是相关类型的对象（继承同一父类或者接口的一组子类），由给定的参数来决定创建哪种类型的对象。\n- 建造者模式是用来创建一种类型的复杂对象，通过设置不同的可选参数，“定制化”地创建不同的对象。\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之工厂模式","url":"/posts/bf53f1b3.html","content":"\n工厂模式可以细分为：简单工厂、工厂方法和抽象工厂三种模式\n\n## 使用场景\n\n总体而言工厂模式的使用场景分为两种：\n\n1. 单个对象的创建过程比较复杂，如需要做复杂初始化操作的对象\n2. 需要根据不同的类型创建不同的对象\n\n针对细分的三种模式，使用场景又可以区分：\n\n1. 当**对象的创建逻辑简单**，通常只需要 new 一下就可以，此时可以考虑**简单工厂模式**\n2. 当**对象的创建逻辑很复杂**，需要做各种初始化操作，此时可以考虑使用**工厂方法模式**，将对象创建的复杂逻辑拆分到各个工厂类中，让每个工厂类都不至于过于复杂\n3. 当**系统中有多于一个产品族**，而每次只使用其中某一产品族，此时使用**抽象工厂模式**\n\n## 简单工厂模式\n\n### 类图\n\n![](https://cdn.wenzuo.net/assets/202201211600141.png)\n\nProcuctA 和 ProductB 继承 Product 抽象类，ProductFactory 根据传入的 type 来返回不同的 Product 实例\n\n### 代码实现\n\n#### Product\n\n```java\npublic abstract class Product {\n    public abstract void use();\n}\n```\n\n#### ProductA\n\n```java\npublic class ProductA extends Product {\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductA...\");\n    }\n}\n```\n\n#### ProductB\n\n```java\npublic class ProductB extends Product {\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductB...\");\n    }\n}\n```\n\n#### ProductFactory\n\n```java\npublic class ProductFactory {\n    public Product createProduct(String type) {\n        Product product = null;\n        if (\"A\".equals(type)) {\n            product = new ProductA();\n        } else if (\"B\".equals(type)) {\n            product = new ProductB();\n        }\n        return product;\n    }\n}\n```\n\n#### Main\n\n```java\npublic class Main {\n    public static void main(String[] args) {\n        ProductFactory factory = new ProductFactory();\n        Product product;\n\n        product = factory.createProduct(\"A\");\n        product.use();\n\n        product = factory.createProduct(\"B\");\n        product.use();\n    }\n}\n```\n\n### 点评\n\n当频繁的新增不同产品时，需要频繁的修改`ProductFactory`中的`if/else`逻辑\n\n### 应用\n\nJDK\n\n```java\njava.text.DateFormat#getDateInstance()\njava.text.DateFormat#getDateInstance(int)\njava.text.DateFormat#getDateInstance(int, java.util.Locale)\n```\n\n加密类，获取不同加密算法的密钥生成器:\n\n```java\nKeyGenerator keyGen=KeyGenerator.getInstance(\"DESede\");\n```\n\n## 工厂方法模式\n\n### 类图\n\n![](https://cdn.wenzuo.net/assets/202201211636855.png)\n\n相比简单工厂，这种方式将`ProductFactory`定义为抽象类，然后创建不同的具体的`ProductAFactory`和`ProductBFactory`，在使用时决定创建那种工厂和对象，避免了 if/else 判断\n\n### 代码实现\n\n#### Product\n\n```java\npublic abstract class Product {\n    public abstract void use();\n}\n```\n\n#### ProductA\n\n```java\npublic class ProductA extends Product {\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductA...\");\n    }\n}\n```\n\n#### ProductB\n\n```java\npublic class ProductB extends Product {\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductB...\");\n    }\n}\n```\n\n#### ProductFactory\n\n```java\npublic abstract class ProductFactory {\n    public abstract Product createProduct();\n}\n```\n\n#### ProductAFactory\n\n```java\npublic class ProductAFactory extends ProductFactory {\n    @Override\n    public Product createProduct() {\n        return new ProductA();\n    }\n}\n```\n\n#### ProductBFactory\n\n```java\npublic class ProductBFactory extends ProductFactory {\n    @Override\n    public Product createProduct() {\n        return new ProductB();\n    }\n}\n```\n\n#### Main\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        ProductFactory factory;\n        Product product;\n\n        factory = new ProductAFactory();\n        product = factory.createProduct();\n        product.use();\n\n        factory = new ProductBFactory();\n        product = factory.createProduct();\n        product.use();\n    }\n\n}\n```\n\n### 点评\n\n这种模式更加符合开闭原则，但是与最原始的`new ProductA()`和`new ProductA()`相比非常相似，引入工厂模式，反倒让设计变得更加复杂了。\n\n### 应用\n\nJDBC\n\n```java\nConnection conn=DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/db1\",\"db_user\",\"123456\");\nStatement statement=conn.createStatement();\nResultSet rs=statement.executeQuery(\"select * from user\");\n```\n\n## 抽象工厂模式\n\n为了理解抽象工厂模式，我们要先了解两个概念：\n\n- 产品等级结构 ：产品等级结构即产品的继承结构，如一个抽象类是电视机，其子类有海尔电视机、海信电视机、TCL 电视机，则抽象电视机与具体品牌的电视机之间构成了一个产品等级结构，抽象电视机是父类，而具体品牌的电视机是其子类。\n- 产品族 ：在抽象工厂模式中，产品族是指由同一个工厂生产的，位于不同产品等级结构中的一组产品，如海尔电器工厂生产的海尔电视机、海尔电冰箱，海尔电视机位于电视机产品等级结构中，海尔电冰箱位于电冰箱产品等级结构中。\n\n在工厂方法模式中具体工厂负责生产具体的产品，每一个具体工厂对应一种具体产品。一般情况下，一个具体工厂中只有一个工厂方法或者一组重载的工厂方法。但是有时候我们需要一个工厂可以提供多个产品对象，而不是单一的产品对象。\n\n### 类图\n\n![](https://cdn.wenzuo.net/assets/202201221006832.png)\n\n`Factory1`负责创建`ProductA1`和`ProductB1`\n`Factory2`负责创建`ProductA2`和`ProductB2`\n客户端不需要知道具体的产品，只需要知道创建的工厂即可使用该产品\n\n### 代码实现\n\n#### AbstractProductA\n\n```java\npublic abstract class AbstractProductA {\n\n    public abstract void use();\n\n}\n```\n\n#### ProductA1\n\n```java\npublic class ProductA1 extends AbstractProductA {\n\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductA1...\");\n    }\n\n}\n```\n\n#### ProductA2\n\n```java\npublic class ProductA2 extends AbstractProductA {\n\n    @Override\n    public void use() {\n        System.out.println(\"You are using ProductA2...\");\n    }\n\n}\n```\n\n#### AbstractProductB\n\n```java\npublic abstract class AbstractProductB {\n\n    public abstract void eat();\n\n}\n```\n\n#### ProductB1\n\n```java\npublic class ProductB1 extends AbstractProductB {\n\n    @Override\n    public void eat() {\n        System.out.println(\"You are eating ProductB1...\");\n    }\n\n}\n```\n\n#### ProductB2\n\n```java\npublic class ProductB2 extends AbstractProductB {\n\n    @Override\n    public void eat() {\n        System.out.println(\"You are eating ProductB2...\");\n    }\n\n}\n```\n\n#### AbstractFactory\n\n```java\npublic abstract class AbstractFactory {\n\n    public abstract AbstractProductA createProductA();\n\n    public abstract AbstractProductB createProductB();\n\n}\n```\n\n#### Factory1\n\n```java\npublic class Factory1 extends AbstractFactory {\n\n    @Override\n    public AbstractProductA createProductA() {\n        return new ProductA1();\n    }\n\n    @Override\n    public AbstractProductB createProductB() {\n        return new ProductB1();\n    }\n\n}\n```\n\n#### Factory2\n\n```java\npublic class Factory2 extends AbstractFactory {\n\n    @Override\n    public AbstractProductA createProductA() {\n        return new ProductA2();\n    }\n\n    @Override\n    public AbstractProductB createProductB() {\n        return new ProductB2();\n    }\n\n}\n```\n\n#### Main\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        AbstractFactory factory;\n\n        factory = new Factory1();\n        use(factory);\n\n        factory = new Factory2();\n        use(factory);\n    }\n\n    public static void use(AbstractFactory factory) {\n        AbstractProductA productA = factory.createProductA();\n        productA.use();\n        AbstractProductB productB = factory.createProductB();\n        productB.eat();\n    }\n\n}\n```\n\n### 点评\n\n抽象工厂模式带来了众多类，结构相对复杂，且创建新的产品等级结构麻烦。\n抽象工厂模式实际工作中应用场景很少，简单关注了解下即可\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之单例模式","url":"/posts/1a4b62fe.html","content":"\n单例设计模式理解起来非常简单。一个类只允许创建一个对象（或者实例），那这个类就是一个单例类，这种设计模式就叫单例模式。\n\n## 使用场景\n\n### 处理资源访问冲突\n\n下面的示例中如果每个类都创建一个 Logger 实例，就可能造成日志内容被覆盖的情况。\n\n```java\npublic class Logger {\n  private FileWriter writer;\n\n  public Logger() {\n    File file = new File(\"log.txt\");\n    writer = new FileWriter(file, true); //true表示追加写入\n  }\n\n  public void log(String message) {\n    writer.write(mesasge);\n  }\n}\n\n\npublic class UserController {\n  private Logger logger = new Logger();\n\n  public void login(String username, String password) {\n    // ...省略业务逻辑代码...\n    logger.log(username + \" logined!\");\n  }\n}\n\npublic class OrderController {\n  private Logger logger = new Logger();\n\n  public void create(OrderVo order) {\n    // ...省略业务逻辑代码...\n    logger.log(\"Created an order: \" + order.toString());\n  }\n}\n```\n\n### 表示全局唯一类\n\n如果有些数据在系统中只应保存一份，那就比较适合设计为单例类。比如，配置信息类，全局 ID 生成器等。\n\n## 如何实现一个单例？\n\n要实现一个单例，我们要考虑以下几点：\n\n- 构造函数需要是 private 访问权限的，这样才能避免外部通过 new 创建实例；\n- 考虑对象创建时的线程安全问题；\n- 考虑是否支持延迟加载；\n- 考虑 getInstance() 性能是否高（是否加锁）。\n\n### 饿汉式\n\n```java\npublic class Singleton {\n  private static final Singleton instance = new Singleton();\n\n  private Singleton() {}\n\n  public static Singleton getInstance() {\n    return instance;\n  }\n}\n```\n\n### 懒汉式\n\n懒汉式相对于饿汉式的优势是**支持延迟加载**。但缺点也很明显，因为使用了`synchronized`关键字导致这个方法的**并发度很低**。如果这个单例类偶尔会被用到，那这种实现方式还可以接受。但是，如果频繁地用到，就会导致性能瓶颈，这种实现方式就不可取了。\n\n```java\npublic class Singleton {\n  private static Singleton instance;\n\n  private Singleton() {}\n\n  public static synchronized Singleton getInstance() {\n    if (instance == null) {\n      instance = new Singleton();\n    }\n    return instance;\n  }\n}\n```\n\n### 双重检测\n\n这是一种既支持延迟加载、又支持高并发的单例实现方式。\n\n```java\npublic class Singleton {\n  private static Singleton instance;\n\n  private Singleton() {}\n\n  public static Singleton getInstance() {\n    if (instance == null) {\n      synchronized(Singleton.class) { // 此处为类级别的锁\n        if (instance == null) {\n          instance = new Singleton();\n        }\n      }\n    }\n    return instance;\n  }\n}\n```\n\n在 java1.5 以下`instance = new Singleton();`有指令重排问题，需要给`instance`成员变量加上`volatile`关键字，java1.5 之后不会再这个有问题。\n\n### 静态内部类\n\n这种方式利用了 Java 的静态内部类，有点类似饿汉式，但又能做到了延迟加载。\n\n当外部类 Singleton 被加载的时候，并不会创建 SingletonHolder 实例对象。只有当调用 getInstance() 方法时，SingletonHolder 才会被加载，这个时候才会创建 instance。insance 的唯一性、创建过程的线程安全性，都由 JVM 来保证。所以，这种实现方法既保证了线程安全，又能做到延迟加载。\n\n```java\npublic class Singleton {\n  private Singleton() {}\n\n  private static class SingletonHolder{\n    private static final Singleton instance = new Singleton();\n  }\n\n  public static Singleton getInstance() {\n    return SingletonHolder.instance;\n  }\n}\n```\n\n### 枚举\n\n这是一种最简单的实现方式，基于枚举类型的单例实现。这种实现方式通过 Java 枚举类型本身的特性，保证了实例创建的线程安全性和实例的唯一性。\n\n```java\npublic enum IdGenerator {\n  INSTANCE;\n  private AtomicLong id = new AtomicLong(0);\n\n  public long getId() {\n    return id.incrementAndGet();\n  }\n}\n```\n\n## 如何实现线程唯一的单例？\n\n上面的单例类对象是进程唯一的，一个进程只能有一个单例对象。那如何实现一个线程唯一的单例呢？\n\n假设 IdGenerator 是一个线程唯一的单例类。在线程 A 内，我们可以创建一个单例对象 a。因为线程内唯一，在线程 A 内就不能再创建新的 IdGenerator 对象了，而线程间可以不唯一，所以，在另外一个线程 B 内，我们还可以重新创建一个新的单例对象 b。\n\n我们通过一个 ConcurrentHashMap 来存储对象，其中 key 是线程 ID，value 是对象。这样我们就可以做到，不同的线程对应不同的对象，同一个线程只能对应一个对象。实际上，Java 语言本身提供了 ThreadLocal 工具类，可以更加轻松地实现线程唯一单例。\n\n```java\npublic class IdGenerator {\n  private AtomicLong id = new AtomicLong(0);\n\n  private static final ConcurrentHashMap<Long, IdGenerator> instances\n          = new ConcurrentHashMap<>();\n\n  private IdGenerator() {}\n\n  public static IdGenerator getInstance() {\n    Long currentThreadId = Thread.currentThread().getId();\n    instances.putIfAbsent(currentThreadId, new IdGenerator());\n    return instances.get(currentThreadId);\n  }\n\n  public long getId() {\n    return id.incrementAndGet();\n  }\n}\n```\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"设计模式之设计原则","url":"/posts/4a7ab732.html","content":"\n> SOLID 原则是由五个设计原则组成：单一职责原则（SRP），开闭原则（OCP），里式替换原则（LSP），接口隔离原则（ISP），依赖反转原则（DIP）\n\n## 单一职责原则（SRP）\n\n### 概念\n\n单一职责原则的英文是 Single Responsibility Principle，缩写为 SRP。\n\n**一个类只负责完成一个职责或者功能**。不要设计大而全的类，要设计粒度小、功能单一的类。单一职责原则是为了实现代码高内聚、低耦合，提高代码的复用性、可读性、可维护性。\n\n### 如何判断类的职责是否足够单一？\n\n不同的应用场景、不同阶段的需求背景、不同的业务层面，对同一个类的职责是否单一，可能会有不同的判定结果。\n\n一些侧面的判断指标更具有指导意义和可执行性，比如，出现下面这些情况就有可能说明这类的设计不满足单一职责原则：\n\n- 类中的代码行数、函数或者属性过多；\n\n- 类依赖的其他类过多，或者依赖类的其他类过多；\n\n- 私有方法过多；\n\n- 比较难给类起一个合适的名字；\n\n- 类中大量的方法都是集中操作类中的某几个属性。\n\n### 类的职责是否设计得越单一越好？\n\n单一职责原则是为了实现代码高内聚、低耦合，如果拆分得过细，实际上会适得其反，反倒会降低内聚性，也会影响代码的可维护性。\n\n## 开闭原则（OCP）\n\n### 概念\n\n开闭原则的英文全称是 Open Closed Principle，简写为 OCP。\n\n**软件实体（模块、类、方法等）应该“对扩展开放、对修改关闭”**。\n\n添加一个新的功能，应该是通过在已有代码基础上扩展代码（新增模块、类、方法、属性等），而非修改已有代码（修改模块、类、方法、属性等）的方式来完成。关于定义，我们有两点要注意。第一点是，开闭原则**并不是说完全杜绝修改**，而是以最小的修改代码的代价来完成新功能的开发。第二点是，同样的代码改动，在粗代码粒度下，可能被认定为“修改”；在细代码粒度下，可能又被认定为“扩展”。\n\n### 如何做到“对扩展开放、修改关闭”？\n\n我们要时刻具备扩展意识、抽象意识、封装意识，在写代码的时候，多思考这段代码未来可能有哪些需求变更，如何设计代码结构，事先留好扩展点，以便将新的代码灵活地插入到扩展点上。\n\n23 种经典设计模式，大部分都是为了解决代码的扩展性问题而总结出来的，都是以开闭原则为指导原则的。最常用来提高代码扩展性的方法有：多态、依赖注入、基于接口而非实现编程，以及大部分的设计模式（比如，装饰、策略、模板、职责链、状态）。\n\n## 里式替换原则（LSP）\n\n### 概念\n\n里式替换原则的英文翻译是：Liskov Substitution Principle，缩写为 LSP。\n\n**子类对象能够替换程序中父类对象出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏。**\n\n里式替换原则是用来指导，继承关系中子类该如何设计的一个原则。理解里式替换原则，最核心的就是理解“design by contract，按照协议来设计”这几个字。父类定义了函数的“约定”（或者叫协议），那子类可以改变函数的内部实现逻辑，但不能改变函数原有的“约定”。这里的约定包括：函数声明要实现的功能；对输入、输出、异常的约定；甚至包括注释中所罗列的任何特殊说明。\n\n### 里式替换原则跟多态的区别\n\n虽然从定义描述和代码实现上来看，多态和里式替换有点类似，但它们关注的角度是不一样的。多态是面向对象编程的一大特性，也是面向对象编程语言的一种语法。它是一种代码实现的思路。而里式替换是一种设计原则，用来指导继承关系中子类该如何设计，子类的设计要保证在替换父类的时候，不改变原有程序的逻辑及不破坏原有程序的正确性。\n\n## 接口隔离原则（ISP）\n\n### 概念\n\n接口隔离原则的英文翻译是“ Interface Segregation Principle”，缩写为 ISP。\n\n**客户端不应该强迫依赖它不需要的接口。其中的“客户端”，可以理解为接口的调用者或者使用者。**\n\n接口的设计要尽量单一，不要让接口的实现类和调用者，依赖不需要的接口函数。\n\n### 接口隔离原则与单一职责原则的区别\n\n单一职责原则针对的是模块、类、接口的设计。接口隔离原则相对于单一职责原则，一方面更侧重于接口的设计，另一方面它的思考角度也是不同的。接口隔离原则提供了一种判断接口的职责是否单一的标准：通过调用者如何使用接口来间接地判定。如果调用者只使用部分接口或接口的部分功能，那接口的设计就不够职责单一。\n\n## 依赖反转原则（DIP）\n\n### 概念\n\n依赖反转原则。依赖反转原则的英文翻译是 Dependency Inversion Principle，缩写为 DIP。\n\n**高层模块不要依赖低层模块。高层模块和低层模块应该通过抽象来互相依赖。除此之外，抽象不要依赖具体实现细节，具体实现细节依赖抽象。**\n\n所谓高层模块和低层模块的划分，简单来说就是，在调用链上，调用者属于高层，被调用者属于低层。\n\n### 控制反转（IOC）\n\n这里的“控制”指的是对程序执行流程的控制，而“反转”指的是在没有使用框架之前，程序员自己控制整个程序的执行。在使用框架之后，整个程序的执行流程可以通过框架来控制。流程的控制权从程序员“反转”到了框架。\n\n实现控制反转的方法有很多，控制反转并不是一种具体的实现技巧，而是一个比较笼统的设计思想，一般用来指导框架层面的设计。\n\n### 依赖注入（DI）\n\n什么是依赖注入呢？我们用一句话来概括就是：不通过 new() 的方式在类内部创建依赖类对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递（或注入）给类使用。\n\n## KISS 原则\n\n### 概念\n\nKISS 原则。英文是 Keep It Simple and Stupid，缩写为 KISS。\n\n**尽量保持简单**\n\nKISS 原则中的“简单”并不是以代码行数来考量的。代码行数越少并不代表代码越简单，我们还要考虑逻辑复杂度、实现难度、代码的可读性等。而且，本身就复杂的问题，用复杂的方法解决，并不违背 KISS 原则。除此之外，同样的代码，在某个业务场景下满足 KISS 原则，换一个应用场景可能就不满足了。\n\n### 对于如何写出满足 KISS 原则的代码\n\n- 不要使用同事可能不懂的技术来实现代码；\n\n- 不要重复造轮子，要善于使用已经有的工具类库；\n\n- 不要过度优化。\n\n## DRY 原则\n\n### 概念\n\nDRY 原则为 Don’t Repeat Yourself\n\n**不要重复造轮子**\n\n实现逻辑重复，但功能语义不重复的代码，并不违反 DRY 原则。实现逻辑不重复，但功能语义重复的代码，也算是违反 DRY 原则。除此之外，代码执行重复也算是违反 DRY 原则。\n\n### 提高代码可复用性的一些方法\n\n- 减少代码耦合\n\n- 满足单一职责原则\n\n- 模块化\n\n- 业务与非业务逻辑分离\n\n- 通用代码下沉\n\n- 继承、多态、抽象、封装\n\n- 应用模板等设计模式\n\n我们在第一次写代码的时候，如果当下没有复用的需求，而未来的复用需求也不是特别明确，并且开发可复用代码的成本比较高，那我们就不需要考虑代码的复用性。在之后开发新的功能的时候，发现可以复用之前写的这段代码，那我们就重构这段代码，让其变得更加可复用。\n\n相比于代码的可复用性，DRY 原则适用性更强一些。我们可以不写可复用的代码，但一定不能写重复的代码。\n\n# 迪米特法则（LOD）\n\n### 概念\n\n迪米特法则的英文翻译是：Law of Demeter，缩写是 LOD。它还有另外一个更加达意的英文翻译为：The Least Knowledge Principle。\n\n**最小知识原则**\n\n每个模块只应该了解那些与它关系密切的模块的有限知识。\n\n不该有直接依赖关系的类之间，不要有依赖。有依赖关系的类之间，尽量只依赖必要的接口。迪米特法则是希望减少类之间的耦合，让类越独立越好。每个类都应该少了解系统的其他部分。一旦发生变化，需要了解这一变化的类就会比较少。\n\n### 如何理解“高内聚、松耦合”？\n\n所谓高内聚，就是指相近的功能应该放到同一个类中，不相近的功能不要放到同一类中。相近的功能往往会被同时修改，放到同一个类中，修改会比较集中。\n\n所谓松耦合指的是，在代码中，类与类之间的依赖关系简单清晰。即使两个类有依赖关系，一个类的代码改动也不会或者很少导致依赖类的代码改动。\n","tags":["设计模式"],"categories":["编程笔记"]},{"title":"最重要的JVM参数指南","url":"/posts/a258c787.html","content":"\n## 概述\n\n在这个快速教程中，我们将探索可用于配置 Java 虚拟机的最知名的选项。\n\n## 堆内存 -Xms 和 -Xmx\n\n最常见的与性能相关的实践之一是根据应用程序需求初始化堆内存。\n\n这就是为什么我们应该指定最小和最大的堆大小:\n\n```\n-Xms<heap size>[unit]\n-Xmx<heap size>[unit]\n```\n\n<!-- more -->\n\n在这里，unit 表示要初始化内存(用堆大小表示)的单元。单位可以标记为“ g”为 GB，“ m”为 MB，“ k”为 KB。\n例如，如果我们想给 JVM 分配最小的 2gb 和最大的 5gb，我们需要写:\n\n```\n-Xms2G -Xmx5G\n```\n\n从 java8 开始，Metaspace 的大小没有定义。一旦它达到全局限制，JVM 会自动增加它，然而，为了克服任何不必要的不稳定性，我们可以设置 Metaspace 大小为:\n\n```\n-XX:MaxMetaspaceSize=<metaspace size>[unit]\n```\n\n在这里，元/空间大小表示我们要分配给元/空间的内存量。\n根据 Oracle 的指导方针，除了总的可用内存之外，第二大影响因素是为年轻一代保留的堆的比例。默认情况下，YG 的最小大小为 1310 MB，最大大小不受限制。\n我们可以明确地分配它们:\n\n```\n-XX:NewSize=<young size>[unit]\n-XX:MaxNewSize=<young size>[unit]\n```\n\n## 垃圾收集\n\n为了提高应用程序的稳定性，选择正确的垃圾收集算法至关重要。\n\n有四种类型的 GC 实现:\n\n- Serial Garbage Collector 串行垃圾收集器\n- Parallel Garbage Collector 并行垃圾收集器\n- CMS Garbage Collector CMS 垃圾收集器\n- G1 Garbage Collector G1 垃圾收集器\n- Z Garbage Collector ZGC 垃圾收集器\n\n这些实现可以使用以下参数声明:\n\n```\n-XX:+UseSerialGC\n-XX:+UseParallelGC\n-XX:+UseParNewGC (会自动启用-XX:+UseConcMarkSweepGC)\n-XX:+UseG1GC\n-XX:+UnlockExperimentalVMOptions -XX:+UseZGC (java11开始支持,java15之后不再需要-XX:+UnlockExperimentalVMOptions)\n```\n\n有关垃圾收集实现的更多详细信息可以在[这里](https://www.baeldung.com/jvm-garbage-collectors)找到。\n\n## GC Logging\n\n为了严格监视应用程序的运行状况，我们应该始终检查 JVM 的垃圾收集性能。最简单的方法是以人类可读的格式记录 GC 活动。\n\n使用以下参数，我们可以记录 GC 活动:\n\n```\n-XX:+UseGCLogFileRotation\n-XX:NumberOfGCLogFiles=< number of log files >\n-XX:GCLogFileSize=< file size >[ unit ]\n-Xloggc:/path/to/gc.log\n```\n\nUseGCLogFileRotation 指定日志文件滚动策略，很像 log4j、 s4lj 等。NumberOfGCLogFiles 表示可以为单个应用程序生命周期编写的日志文件的最大数量。GCLogFileSize 指定文件的最大大小。最后，loggc 表示它的位置。\n\n这里需要注意的是，还有两个可用的 JVM 参数(-XX:+PrintGCTimeStamps 和 -XX:+PrintGCDateStamps)可用于在 GC 日志中打印日期时间戳。\n\n例如，如果我们希望分配最多 100 个 GC 日志文件，每个文件的最大大小为 50 MB，并希望将它们存储在‘/home/user/log/’位置，我们可以使用以下语法:\n\n```\n-XX:+UseGCLogFileRotation\n-XX:NumberOfGCLogFiles=10\n-XX:GCLogFileSize=50M\n-Xloggc:/home/user/log/gc.log\n```\n\n但是，问题是总是在后台使用一个附加的守护进程线程来监视系统时间。**这种行为可能会造成一些性能瓶颈; 这就是为什么在生产中最好不要使用这个参数的原因。**\n\n## 处理 OOM\n\n对于大型应用程序来说，面对内存不足错误是非常常见的，这反过来会导致应用程序崩溃。这是一个非常关键的场景，很难通过复制来解决这个问题。\n\n这就是为什么 JVM 提供了一些参数，这些参数将堆内存转储到一个物理文件中，以后可以用来查找泄漏:\n\n```\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:HeapDumpPath=./java_pid<pid>.hprof\n-XX:OnOutOfMemoryError=\"< cmd args >;< cmd args >\"\n-XX:+UseGCOverheadLimit\n```\n\n这里有几点需要注意:\n\n- HeapDumpOnOutOfMemoryError 指示 JVM 在遇到 OutOfMemoryError 错误时将 heap 转储到物理文件中\n- HeapDumpPath 表示要写入文件的路径; 可以给出任何文件名; 但是，如果 JVM 在名称中找到一个 `<pid>` 标记，则当前进程的进程 id 将附加到文件名中，并使用`.hprof`格式\n  OnOutOfMemoryError is used to issue emergency commands to be executed in case of out of memory error; proper command should be used in the space of cmd args. For example, if we want to restart the server as soon as out of memory occur, we can set the parameter:\n- OnOutOfMemoryError 用于发出紧急命令，以便在内存不足的情况下执行; 应该在 `cmd args` 空间中使用适当的命令。例如，如果我们想在内存不足时重启服务器，我们可以设置参数:\n\n```\n-XX:OnOutOfMemoryError=\"shutdown -r\"\n```\n\n- UseGCOverheadLimit 是一种策略，它限制在抛出 OutOfMemory 错误之前在 GC 中花费的 VM 时间的比例\n\n## 32/64 位\n\n在同时安装了 32 位和 64 位包的操作系统环境中，JVM 会自动选择 32 位环境包。\n\n如果我们想手动设置环境为 64 位，我们可以使用下面的参数:\n\n```\n-d<OS bit>\n```\n\n操作系统位可以是 32 或 64。更多信息可以在[这里](http://www.oracle.com/technetwork/java/hotspotfaq-138619.html#64bit_layering)找到。\n\n## 杂项\n\n- server: 启用“ Server Hotspot VM”; 此参数默认用于 64 位 JVM\n- -XX:+UseStringDeduplication: java8u20 引入了这个 JVM 参数，通过创建太多相同 String 的实例来减少不必要的内存使用; 这通过将重复 String 值减少为单个全局 char []数组来优化堆内存\n- -XX:+UseLWPSynchronization: 设置基于 LWP (轻量级进程)的同步策略，而不是基于线程的同步\n- -XX:LargePageSizeInBytes: 设置用于 Java 堆的较大页面大小; 它采用 GB/MB/KB 的参数; 页面大小越大，我们可以更好地利用虚拟内存硬件资源; 然而，这可能会导致 PermGen 的空间大小更大，这反过来又会迫使 Java 堆空间的大小减小\n- -XX:MaxHeapFreeRatio: 设置 GC 后, 堆空闲的最大百分比，以避免收缩。\n- -XX:SurvivorRatio: eden/survivor 空间的比例, 例如`-XX:SurvivorRatio=6` 设置每个 survivor 和 eden 之间的比例为 1:6,\n- -XX:+UseLargePages: 如果系统支持，则使用大页面内存; 请注意，如果使用这个 JVM 参数，OpenJDK 7 可能会崩溃\n- -XX:+UseStringCache: 启用 String 池中可用的常用分配字符串的缓存\n- -XX:+UseCompressedStrings: 对 String 对象使用 byte []类型，该类型可以用纯 ASCII 格式表示\n- -XX:+OptimizeStringConcat: 它尽可能优化字符串串联操作\n\n## 总结\n\n我们了解了一些重要的 JVM 参数，这些参数可用于调优和提高通用应用程序性能。\n\n其中一些还可以用于调试目的。\n\n如果您想更详细地研究参考参数，可以从[这里](http://www.oracle.com/technetwork/articles/java/vmoptions-jsp-140102.html)开始。\n\n## 相关链接\n\n[Guide to the Most Important JVM Parameters](https://www.baeldung.com/jvm-parameters)\n[JVM Garbage Collectors](https://www.baeldung.com/jvm-garbage-collectors)\n[Oracle Java HotSpot VM Options](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html)\n[Oracle HotSpot FAQ](https://www.oracle.com/java/technologies/hotspotfaq.html#64bit_layering)\n","tags":["Java","JVM"],"categories":["编程笔记"]},{"title":"Java Volatile关键字","url":"/posts/551c330e.html","content":"\n> 原文地址 作者：Jakob Jenkov 译者：小龙虾\n>\n> _转载自_[并发编程网 – ifeve.com](http://ifeve.com/)\n\nJava 的 volatile 关键字用于标记一个变量“应当存储在主存”。更确切地说，每次读取 volatile 变量，都应该从主存读取，而不是从 CPU 缓存读取。每次写入一个 volatile 变量，应该写到主存中，而不是仅仅写到 CPU 缓存。\n\n实际上，从 Java 5 开始，volatile 关键字除了保证 volatile 变量从主存读写外，还提供了更多的保障。我将在后面的章节中进行说明。\n\n<!-- more -->\n\n## 变量可见性问题\n\nJava 的 volatile 关键字能保证变量修改后，对各个线程是可见的。这个听起来有些抽象，下面就详细说明。\n\n在一个多线程的应用中，线程在操作非 volatile 变量时，出于性能考虑，每个线程可能会将变量从主存拷贝到 CPU 缓存中。如果你的计算机有多个 CPU，每个线程可能会在不同的 CPU 中运行。这意味着，每个线程都有可能会把变量拷贝到各自 CPU 的缓存中，如下图所示：\n\n![img](https://cdn.wenzuo.net/assets/202109181009180.png)\n\n对于非 volatile 变量，JVM 并不保证会从主存中读取数据到 CPU 缓存，或者将 CPU 缓存中的数据写到主存中。这会引起一些问题，在后面的章节中，我会来解释这些问题。\n\n试想一下，如果有两个以上的线程访问一个共享对象，这个共享对象包含一个 counter 变量，下面是代码示例：\n\n```java\npublic class SharedObject {\n\n    public int counter = 0;\n\n}\n```\n\n如果只有线程 1 修改了（自增）counter 变量，而线程 1 和线程 2 两个线程都会在某些时刻读取 counter 变量。\n\n如果 counter 变量没有声明成 volatile，则 counter 的值不保证会从 CPU 缓存写回到主存中。也就是说，CPU 缓存和主存中的 counter 变量值并不一致，如下图所示：\n\n![img](https://cdn.wenzuo.net/assets/202109181009963.png)\n\n这就是“可见性”问题，线程看不到变量最新的值，因为其他线程还没有将变量值从 CPU 缓存写回到主存。一个线程中的修改对另外的线程是不可见的。\n\n## volatile 可见性保证\n\nJava 的 volatile 关键字就是设计用来解决变量可见性问题。将 counter 变量声明为 volatile，则在写入 counter 变量时，也会同时将变量值写入到主存中。同样的，在读取 counter 变量值时，也会直接从主存中读取。\n\n下面的代码演示了如果将 counter 声明为 volatile：\n\n```java\npublic class SharedObject {\n\n    public volatile int counter = 0;\n\n}\n```\n\n将一个变量声明为 volatile，可以保证变量写入时对其他线程的可见。\n\n在上面的场景中，一个线程（T1）修改了 counter，另一个线程（T2）读取了 counter（但没有修改它），将 counter 变量声明为 volatile，就能保证写入 counter 变量后，对 T2 是可见的。\n\n然而，如果 T1 和 T2 都修改了 counter 的值，只是将 counter 声明为 volatile 还远远不够，后面会有更多的说明。\n\n## 完整的 volatile 可见性保证\n\n实际上，volatile 的可见性保证并不是只对于 volatile 变量本身那么简单。可见性保证遵循以下规则：\n\n- 如果线程 A 写入一个 volatile 变量，线程 B 随后读取了同样的 volatile 变量，则线程 A 在写入 volatile 变量之前的所有可见的变量值，在线程 B 读取 volatile 变量后也同样是可见的。\n- 如果线程 A 读取一个 volatile 变量，那么线程 A 中所有可见的变量也会同样从主存重新读取。\n\n下面用一段代码来示例说明：\n\n```java\npublic class MyClass {\n    private int years;\n    private int months\n    private volatile int days;\n\n\n    public void update(int years, int months, int days){\n        this.years  = years;\n        this.months = months;\n        this.days   = days;\n    }\n}\n```\n\nupdate()方法写入 3 个变量，其中只有 days 变量是 volatile。\n\n完整的 volatile 可见性保证意味着，在写入 days 变量时，线程中所有可见变量也会写入到主存。也就是说，写入 days 变量时，years 和 months 也会同时被写入到主存。\n\n下面的代码读取了 years、months、days 变量：\n\n```java\npublic class MyClass {\n    private int years;\n    private int months\n    private volatile int days;\n\n    public int totalDays() {\n        int total = this.days;\n        total += months * 30;\n        total += years * 365;\n        return total;\n    }\n\n    public void update(int years, int months, int days){\n        this.years  = years;\n        this.months = months;\n        this.days   = days;\n    }\n}\n```\n\n请注意 totalDays()方法开始读取 days 变量值到 total 变量。在读取 days 变量值时，months 和 years 的值也会同时从主存读取。因此，按上面所示的顺序读取时，可以保证读取到 days、months、years 变量的最新值。\n\n> 译者注：可以将对 volatile 变量的读写理解为一个触发刷新的操作，写入 volatile 变量时，线程中的所有变量也都会触发写入主存。而读取 volatile 变量时，也同样会触发线程中所有变量从主存中重新读取。因此，应当尽量将 volatile 的写入操作放在最后，而将 volatile 的读取放在最前，这样就能连带将其他变量也进行刷新。上面的例子中，update()方法对 days 的赋值就是放在 years、months 之后，就是保证 years、months 也能将最新的值写入到主存，如果是放在两个变量之前，则 days 会写入主存，而 years、months 则不会。反过来，totalDays()方法则将 days 的读取放在最前面，就是为了能同时触发刷新 years、months 变量值，如果是放后面，则 years、months 就可能还是从 CPU 缓存中读取值，而不是从主存中获取最新值。\n\n## 指令重排问题\n\n出于性能考虑，JVM 和 CPU 是允许对程序中的指令进行重排的，只要保证（重排后的）指令语义一致即可。如下代码为例：\n\n```java\nint a = 1;\nint b = 2;\n\na++;\nb++;\n```\n\n这些指令可以按以下顺序重排，而不改变程序的语义：\n\n```java\nint a = 1;\na++;\n\nint b = 2;\nb++;\n```\n\n然而，指令重排面临的一个问题就是对 volatile 变量的处理。还是以前面提到的 MyClass 类来说明：\n\n```java\npublic class MyClass {\n    private int years;\n    private int months\n    private volatile int days;\n\n\n    public void update(int years, int months, int days){\n        this.years  = years;\n        this.months = months;\n        this.days   = days;\n    }\n}\n```\n\n一旦 update()变量写了 days 值，则 years、months 的最新值也会写入到主存。但是，如果 JVM 重排了指令，比如按以下方式重排：\n\n```java\npublic void update(int years, int months, int days){\n    this.days   = days;\n    this.months = months;\n    this.years  = years;\n}\n```\n\n在 days 被修改时，months、years 的值也会写入到主存，但这时进行写入，months、years 并不是新的值（译者注：即在 months、years 被赋新值之前，就触发了这两个变量值写入主存的操作，自然这两个变量在主存中的值就不是新值）。新的值自然对其他线程是不可见的。指令重排导致了程序语义的改变。\n\nJava 对此有一个解决方法，我们会在下一章节中说明。\n\n## Java volatile Happens-Before 保证\n\n为了解决指令重排的问题，Java 的 volatile 关键字在可见性之外，又提供了 happends-before 保证。happens-before 原则如下：\n\n- 如果有读写操作发生在写入 volatile 变量之前，读写其他变量的指令不能重排到写入 volatile 变量之后。写入一个 volatile 变量之前的读写操作，对 volatile 变量是有 happens-before 保证的。注意，如果是写入 volatile 之后，有读写其他变量的操作，那么这些操作指令是有可能被重排到写入 volatile 操作指令之前的。但反之则不成立。即可以把位于写入 volatile 操作指令之后的其他指令移到写入 volatile 操作指令之前，而不能把位于写入 volatile 操作指令之前的其他指令移到写入 volatile 操作指令之后。\n- 如果有读写操作发生在读取 volatile 变量之后，读写其他变量的指令不能重排到读取 volatile 变量之前。注意，如果是读取 volatile 之前，有读取其他变量的操作，那么这些操作指令是有可能被重排到读取 volatile 操作指令之后的。但反之则不成立。即可以把位于读取 volatile 操作指令之前的指令移到读取 volatile 操作指令之后，而不能把位于读取 volatile 操作指令之后的指令移到读取 volatile 操作指令之前。\n\n以上的 happens-before 原则为 volatile 关键字的可见性提供了强制保证。\n\n> 译者注：这两个原则读起来有些拗口（当然翻译也不足够好），其实就是不管 JVM 怎么去禁止/允许某些情况下的指令重排，最终就是保证“完整的 volatile 可见性保证”的那种效果，所以，只要理解了“完整的 volatile 可见性保证”的效果就足够了。\n\n## volatile 并不总是可行的\n\n虽然 volatile 关键字能保证 volatile 变量的所有读取都是直接从主存读取，所有写入都是直接写入到主存中，但在一些情形下，仅仅是将变量声明为 volatile 还是远远不够的。\n\n就像前面示例所说的，线程 1 写入共享变量 counter 的值，将 counter 声明为 volatile 已经足够保证线程 2 总是能获取到最新的值。\n\n事实上，多个线程都能写入共享的 volatile 变量，主存中也能存储正确的变量值，然而这有一个前提，变量新值的写入不能依赖于变量的旧值。换句话说，就是一个线程写入一个共享 volatile 变量值时，不需要先读取变量值，然后以此来计算出新的值。\n\n如果线程需要先读取一个 volatile 变量的值，以此来计算出一个新的值，那么 volatile 变量就不足够保证正确的可见性。（线程间）读写 volatile 变量的时间间隔很短，这将导致一个[竞态条件](http://ifeve.com/race-conditions-and-critical-sections/)，多个线程同时读取了 volatile 变量相同的值，然后以此计算出了新的值，这时各个线程往主存中写回值，则会互相覆盖。\n\n多个线程对 counter 变量进行自增操作就是这样的情形，下面的章节会详细说明这种情形。\n\n设想一下，如果线程 1 将共享变量 counter 的值 0 读取到它的 CPU 缓存，然后自增为 1，而还没有将新值写回到主存。线程 2 这时从主存中读取的 counter 值依然是 0，依然放到它自身的 CPU 缓存中，然后同样将 counter 值自增为 1，同样也还没有将新值写回到主存。如下图所示：\n\n![img](https://cdn.wenzuo.net/assets/202109181015380.png)\n\n从实际的情况来看，线程 1 和线程 2 现在就是不同步的。共享变量 counter 正确的值应该是 2，但各个线程中 CPU 缓存的值都是 1，而主存中的值依然是 0。这是很混乱的。即使线程最终将共享变量 counter 的值写回到主存，那值也明显是错的。\n\n## 何时使用 volatile\n\n正如我前面所说，如果两个线程同时读写一个共享变量，仅仅使用 volatile 关键字是不够的。你应该使用 [synchronized](http://tutorials.jenkov.com/java-concurrency/synchronized.html) 来保证读写变量是原子的。（一个线程）读写 volatile 变量时，不会阻塞（其他）线程进行读写。你必须在关键的地方使用 synchronized 关键字来解决这个问题。\n\n除了 synchronized 方法，你还可以使用[java.util.concurrent](http://tutorials.jenkov.com/java-util-concurrent/index.html)包提供的许多原子数据类型来解决这个问题。比如，[AtomicLong](http://tutorials.jenkov.com/java-util-concurrent/atomiclong.html)或[AtomicReference](http://tutorials.jenkov.com/java-util-concurrent/atomicreference.html)，或是其他的类。\n\n如果只有一个线程对 volatile 进行读写，而其他线程只是读取变量，这时，对于只是读取变量的线程来说，volatile 就已经可以保证读取到的是变量的最新值。如果没有把变量声明为 volatile，这就无法保证。\n\nvolatile 关键字对 32 位和 64 位的变量都有效。\n\n## volatile 的性能考量\n\n读写 volatile 变量会导致变量从主存读写。从主存读写比从 CPU 缓存读写更加“昂贵”。访问一个 volatile 变量同样会禁止指令重排，而指令重排是一种提升性能的技术。因此，你应当只在需要保证变量可见性的情况下，才使用 volatile 变量。\n","tags":["Java","多线程"],"categories":["编程笔记"]},{"title":"The java.util.concurrent Synchronizer Framework 中文翻译版","url":"/posts/11c91f7a.html","content":"\n> 原文：https://raw.githubusercontent.com/sunlggggg/public/master/files/aqs.pdf\n>\n> 作者：Doug Lea\n\n## 摘要\n\n在 J2SE 1.5 的 java.util.concurrent 包（下称 j.u.c 包）中，大部分的同步器（例如锁，屏障等等）都是基于 AbstractQueuedSynchronizer 类（下称 AQS 类），这个简单的框架而构建的。这个框架为同步状态的原子性管理、线程的阻塞和解除阻塞以及排队提供了一种通用的机制。这篇论文主要描述了这个框架基本原理、设计、实现、用法以及性能。\n\n<!-- more -->\n\n## 1. 背景介绍\n\n通过 JCP 的 JSR166 规范，Java 的 1.5 版本引入了 j.u.c 包，这个包提供了一系列支持中等程度并发的类。这些组件是一系列的同步器（抽象数据类型(ADT)）。这些同步器主要维护着以下几个功能：内部同步状态的管理(例如：表示一个锁的状态是获取还是释放)，同步状态的更新和检查操作，且至少有一个方法会导致调用线程在同步状态被获取时阻塞，以及在其他线程改变这个同步状态时解除线程的阻塞。上述的这些的实际例子包括：互斥排它锁的不同形式、读写锁、信号量、屏障、Future、事件指示器以及传送队列等。\n\n几乎任一同步器都可以用来实现其他形式的同步器。例如，可以用可重入锁实现信号量或者用信号量实现可重入锁。但是，这样做带来的复杂性，开销，不灵活使其至多只能是个二流工程。且缺乏吸引力。如果任何这样的构造方式不能在本质上比其他形式更简洁，那么开发者就不应该随意地选择其中的某个来构建另一个同步器。取而代之，JSR166 建立了一个小框架，AQS 类。这个框架为构造同步器提供一种通用的机制，并且被 j.u.c 包中大部分类使用，同时很多用户也用它来定义自己的同步器。\n\n在这篇论文的下面部分会讨论这个框架的需求、设计与实现背后的主要思路、示例用法，以及性能指标的一些测量。\n\n## 2 需求\n\n### 2.1 功能\n\n同步器一般包含两种方法，一种是 acquire，另一种是 release。acquire 操作阻塞调用的线程，直到或除非同步状态允许其继续执行。而 release 操作则是通过某种方式改变同步状态，使得一或多个被 acquire 阻塞的线程继续执行。\n\nj.u.c 包中并没有对同步器的 API 做一个统一的定义。因此，有一些类定义了通用的接口（如 Lock），而另外一些则定义了其专有的版本。因此在不同的类中，acquire 和 release 操作的名字和形式会各有不同。例如：Lock.lock，Semaphore.acquire，CountDownLatch.await 和 FutureTask.get，在这个框架里，这些方法都是 acquire 操作。但是，J.U.C 为支持一系列常见的使用选项，在类间都有个一致约定。在有意义的情况下，每一个同步器都支持下面的操作：\n\n- 阻塞和非阻塞（例如 tryLock）同步。\n- 可选的超时设置，让调用者可以放弃等待\n- 通过中断实现的任务取消，通常是分为两个版本，一个 acquire 可取消，而另一个不可以。\n\n同步器的实现根据其状态是否独占而有所不同。独占状态的同步器，在同一时间只有一个线程可以通过阻塞点，而共享状态的同步器可以同时有多个线程在执行。一般锁的实现类往往只维护独占状态，但是，例如计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架能得到广泛应用，这两种模式都要支持。\n\nj.u.c 包里还定义了 Condition 接口，用于支持管程形式的 await/signal 操作，这些操作与独占模式的 Lock 类有关，且 Condition 的实现天生就和与其关联的 Lock 类紧密相关。\n\n### 2.2 性能目标\n\nJava 内置锁（使用 synchronized 的方法或代码块）的性能问题一直以来都在被人们关注，并且已经有一系列的文章描述其构造（例如引文[1],[3]）。然而，大部分的研究主要关注的是在单核处理器上大部分时候使用于单线程上下文环境中时，如何尽量降低其空间（因为任何的 Java 对象都可以当成是锁）和时间的开销。对于同步器来说这些都不是特别重要：程序员仅在需要的时候才会使用同步器，因此并不需要压缩空间来避免浪费，并且同步器几乎是专门用在多线程设计中（特别是在多核处理器上），在这种环境下，偶尔的竞争是在意料之中的。因此，常规的 JVM 锁优化策略主要是针对零竞争的场景，而其它场景则使用缺乏可预见性的“慢速路径（slow paths）” ，所以常规的 JVM 锁优化策略并不适用于严重依赖于 J.U.C 包的典型多线程服务端应用。\n\n这里主要的性能目标是可伸缩性，即在大部分情况下，即使，或特别在同步器有竞争的情况下，稳定地保证其效率。在理想的情况下，不管有多少线程正试图通过同步点，通过同步点的开销都应该是个常量。在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少，这是主要目标之一。然而，这也必须考虑平衡各种资源，包括总 CPU 时间的需求，内存负载以及线程调度的开销。例如：获取自旋锁通常比阻塞锁所需的时间更短，但是通常也会浪费 CPU 时钟周期，并且造成内存竞争，所以使用的并不频繁。\n\n实现同步器的这些目标包含了两种不同的使用类型。大部分应用程序是最大化其总的吞吐量，容错性，并且最好保证尽量减少饥饿的情况。然而，对于那些控制资源分配的程序来说，更重要是去维持多线程读取的公平性，可以接受较差的总吞吐量。没有任何框架可以代表用户去决定应该选择哪一个方式，因此，应该提供不同的公平策略。\n\n无论同步器的内部实现是多么的精雕细琢，它还是会在某些应用中产生性能瓶颈。因此，框架必须提供相应的监视工具让用户发现和缓和这些瓶颈。至少需要提供一种方式来确定有多少线程被阻塞了。\n\n## 3 设计与实现\n\n同步器背后的基本思想非常简单。acquire 操作如下：\n\n```java\nwhile (synchronization state does not allow acquire) {\n\tenqueue current thread if not already queued;\n\tpossibly block current thread;\n}\ndequeue current thread if it was queued;\n```\n\nrelease 操作如下：\n\n```java\nupdate synchronization state;\nif (state may permit a blocked thread to acquire)\n\tunblock one or more queued threads;\n```\n\n为了实现上述操作，需要下面三个基本组件的相互协作：\n\n- 同步状态的原子性管理；\n- 线程的阻塞与解除阻塞；\n- 队列的管理；\n\n创建一个框架分别实现这三个组件是有可能的。但是，这会让整个框架既难用又没效率。例如：存储在队列节点的信息必须与解除阻塞所需要的信息一致，而暴露出的方法的签名必须依赖于同步状态的特性。\n\n同步器框架的核心决策是为这三个组件选择一个具体实现，同时在使用方式上又有大量选项可用。这里有意地限制了其适用范围，但是提供了足够的效率，使得实际上没有理由在合适的情况下不用这个框架而去重新建造一个。\n\n### 3.1 同步状态\n\nAQS 类使用单个`int`（32 位）来保存同步状态，并暴露出`getState`、`setState`以及`compareAndSet`操作来读取和更新这个状态。这些方法都依赖于 j.u.c.atomic 包的支持，这个包提供了兼容 JSR133 中`volatile`在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现`compareAndSetState`，使得仅当同步状态拥有一个期望值的时候，才会被原子地设置成新值。\n\n将同步状态限制为一个 32 位的整形是出于实践上的考量。虽然 JSR166 也提供了 64 位`long`字段的原子性操作，但这些操作在很多平台上还是使用内部锁的方式来模拟实现的，这会使同步器的性能可能不会很理想。当然，将来可能会有一个类是专门使用 64 位的状态的。然而现在就引入这么一个类到这个包里并不是一个很好的决定（_译者注：JDK1.6 中已经包含`java.util.concurrent.locks.AbstractQueuedLongSynchronizer`类，即使用 long 形式维护同步状态的一个 `AbstractQueuedSynchronizer `版本_）。目前来说，32 位的状态对大多数应用程序都是足够的。在 j.u.c 包中，只有一个同步器类可能需要多于 32 位来维持状态，那就是`CyclicBarrier`类，所以，它用了锁（该包中大多数更高层次的工具亦是如此）。\n\n基于 AQS 的具体实现类必须根据暴露出的状态相关的方法定义`tryAcquire`和`tryRelease`方法，以控制 acquire 和 release 操作。当同步状态满足时，`tryAcquire`方法必须返回`true`，而当新的同步状态允许后续 acquire 时，`tryRelease`方法也必须返回`true`。这些方法都接受一个`int`类型的参数用于传递想要的状态。例如：可重入锁中，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样一个参数，因此忽略它即可。\n\n### 3.2 阻塞\n\n在 JSR166 之前，阻塞线程和解除线程阻塞都是基于 Java 内置管程，没有其它非基于 Java 内置管程的 API 可以用来创建同步器。唯一可以选择的是`Thread.suspend`和`Thread.resume`，但是它们都有无法解决的竞态问题，所以也没法用：当一个非阻塞的线程在一个正准备阻塞的线程调用`suspend`前调用了`resume`，这个`resume`操作将不会有什么效果。\n\nj.u.c 包有一个`LockSuport`类，这个类中包含了解决这个问题的方法。方法`LockSupport.park`阻塞当前线程除非/直到有个`LockSupport.unpark`方法被调用（`unpark`方法被提前调用也是可以的）。`unpark`的调用是没有被计数的，因此在一个`park`调用前多次调用`unpark`方法只会解除一个`park`操作。另外，它们作用于每个线程而不是每个同步器。一个线程在一个新的同步器上调用 park 操作可能会立即返回，因为在此之前可能有“剩余的”`unpark`操作。但是，在缺少一个`unpark`操作时，下一次调用 park 就会阻塞。虽然可以显式地消除这个状态（_译者注：就是多余的`unpark`调用_），但并不值得这样做。在需要的时候多次调用`park`会更高效。\n\n这个简单的机制与有些用法在某种程度上是相似的，例如 Solaris-9 的线程库，WIN32 中的“可消费事件”，以及 Linux 中的 NPTL 线程库。因此最常见的运行 Java 的平台上都有相对应的有效实现。（但目前 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上是使用一个 pthread 的 condvar 来适应目前的运行时设计的）。`park`方法同样支持可选的相对或绝对的超时设置，以及与 JVM 的`Thread.interrupt`结合 —— 可通过中断来`unpark`一个线程。\n\n### 3.3 队列\n\n整个框架的关键就是如何管理被阻塞的线程的队列，该队列是严格的 FIFO 队列，因此，框架不支持基于优先级的同步。\n\n同步队列的最佳选择是自身没有使用底层锁来构造的非阻塞数据结构，目前，业界对此很少有争议。而其中主要有两个选择：一个是 Mellor-Crummey 和 Scott 锁（MCS 锁）[[9\\]](http://ifeve.com/aqs-2/#r9)的变体，另一个是Craig，Landin和Hagersten锁（CLH锁）[[5\\]](http://ifeve.com/aqs-2/#r5)[[8\\]](http://ifeve.com/aqs-2/#r8)[[10\\]](http://ifeve.com/aqs-2/#r10)的变体。一直以来，CLH锁仅被用于自旋锁。但是，在这个框架中，CLH锁显然比MCS锁更合适。因为CLH锁可以更容易地去实现“取消（cancellation）”和“超时”功能，因此我们选择了CLH锁作为实现的基础。但是最终的设计已经与原来的CLH锁有较大的出入，因此下文将对此做出解释。\n\nCLH 队列实际上并不那么像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。它是一个链表队列，通过两个字段`head`和`tail`来存取，这两个字段是可原子更新的，两者在初始化时都指向了一个空节点。\n\n![CLH队列节点间的关系](https://cdn.wenzuo.net/assets/202109172031829.png)\n\n一个新的节点，node，通过一个原子操作入队：\n\n```java\ndo {\n\tpred = tail;\n} while(!tail.compareAndSet(pred, node));\n```\n\n每一个节点的“释放”状态都保存在其前驱节点中。因此，自旋锁的“自旋”操作就如下：\n\n```java\nwhile (pred.status != RELEASED); // spin\n```\n\n自旋后的出队操作只需将 head 字段指向刚刚得到锁的节点：\n\n```java\nhead = node;\n```\n\nCLH 锁的优点在于其入队和出队操作是快速、无锁的，以及无障碍的（即使在竞争下，某个线程总会赢得一次插入机会而能继续执行）；且探测是否有线程正在等待也很快（只要测试一下 head 是否与 tail 相等）；同时，“释放”状态是分散的（_译者注：几乎每个节点都保存了这个状态，当前节点保存了其后驱节点的“释放”状态，因此它们是分散的，不是集中于一块的。_），避免了一些不必要的内存竞争。\n\n在原始版本的 CLH 锁中，节点间甚至都没有互相链接。自旋锁中，`pred`变量可以是一个局部变量。然而，Scott 和 Scherer 证明了通过在节点中显式地维护前驱节点，CLH 锁就可以处理“超时”和各种形式的“取消”：如果一个节点的前驱节点取消了，这个节点就可以滑动去使用前面一个节点的状态字段。\n\n为了将 CLH 队列用于阻塞式同步器，需要做些额外的修改以提供一种高效的方式定位某个节点的后继节点。在自旋锁中，一个节点只需要改变其状态，下一次自旋中其后继节点就能注意到这个改变，所以节点间的链接并不是必须的。但在阻塞式同步器中，一个节点需要显式地唤醒（`unpark`）其后继节点。\n\nAQS 队列的节点包含一个`next`链接到它的后继节点。但是，由于没有针对双向链表节点的类似`compareAndSet`的原子性无锁插入指令，因此这个`next`链接的设置并非作为原子性插入操作的一部分，而仅是在节点被插入后简单地赋值：\n\n```java\npred.next = node;\n```\n\n`next`链接仅是一种优化。如果通过某个节点的`next`字段发现其后继结点不存在（或看似被取消了），总是可以使用`pred`字段从尾部开始向前遍历来检查是否真的有后续节点。\n\n第二个对 CLH 队列主要的修改是将每个节点都有的状态字段用于控制阻塞而非自旋。在同步器框架中，仅在线程调用具体子类中的`tryAcquire`方法返回`true`时，队列中的线程才能从`acquire`操作中返回；而单个“released”位是不够的。但仍然需要做些控制以确保当一个活动的线程位于队列头部时，仅允许其调用`tryAcquire`；这时的`acquire`可能会失败，然后（重新）阻塞。这种情况不需要读取状态标识，因为可以通过检查当前节点的前驱是否为`head`来确定权限。与自旋锁不同，读取`head`以保证复制时不会有太多的内存竞争（ there is not enough memory contention reading head to warrant replication.）。然而，“取消”状态必须存在于状态字段中。\n\n队列节点的状态字段也用于避免没有必要的`park`和`unpark`调用。虽然这些方法跟阻塞原语一样快，但在跨越 Java 和 JVM runtime 以及操作系统边界时仍有可避免的开销。在调用`park`前，线程设置一个“唤醒（signal me）”位，然后再一次检查同步和节点状态。一个释放的线程会清空其自身状态。这样线程就不必频繁地尝试阻塞，特别是在锁相关的类中，这样会浪费时间等待下一个符合条件的线程去申请锁，从而加剧其它竞争的影响。除非后继节点设置了“唤醒”位（_译者注：源码中为-1_），否则这也可避免正在 release 的线程去判断其后继节点。这反过来也消除了这些情形：除非“唤醒”与“取消”同时发生，否则必须遍历多个节点来处理一个似乎为 null 的`next`字段。\n\n同步框架中使用的 CLH 锁的变体与其他语言中的相比，主要区别可能是同步框架中使用的 CLH 锁需要依赖垃圾回收管理节点的内存，这就避免了一些复杂性和开销。但是，即使依赖 GC 也仍然需要在确定链接字段不再需要时将其置为 null。这往往可以与出队操作一起完成。否则，无用的节点仍然可触及，它们就没法被回收。\n\n其它一些更深入的微调，包括 CLH 队列首次遇到竞争时才需要的初始空节点的延迟初始化等，都可以在 J2SE1.5 的版本的源代码文档中找到相应的描述。\n\n抛开这些细节，基本的`acquire`操作的最终实现的一般形式如下（互斥，非中断，无超时）：\n\n```java\nif(!tryAcquire(arg)) {\n\tnode = create and enqueue new node;\n    pred = node's effective predecessor;\n    while (pred is not head node || !tryAcquire(arg)) {\n        if (pred's signal bit is set)\n            pard()\n        else\n            compareAndSet pred's signal bit to true;\n        pred = node's effective predecessor;\n    }\n    head = node;\n}\n```\n\n`release`操作：\n\n```java\nif(tryRelease(arg) && head node's signal bit is set) {\n    compareAndSet head's bit to false;\n    unpark head's successor, if one exist\n}\n```\n\n`acquire`操作的主循环次数依赖于具体实现类中`tryAcquire`的实现方式。另一方面，在没有“取消”操作的情况下，每一个组件的`acquire`和`release`都是一个 O(1)的操作，忽略`park`中发生的所有操作系统线程调度。\n\n支持“取消”操作主要是要在`acquire`循环里的`park`返回时检查中断或超时。由超时或中断而被取消等待的线程会设置其节点状态，然后`unpark`其后继节点。在有“取消”的情况下，判断其前驱节点和后继节点以及重置状态可能需要 O(n)的遍历（n 是队列的长度）。由于“取消”操作，该线程再也不会被阻塞，节点的链接和状态字段可以被快速重建。\n\n### 3.4 条件队列\n\nAQS 框架提供了一个`ConditionObject`类，给维护独占同步的类以及实现`Lock`接口的类使用。一个锁对象可以关联任意数目的条件对象，可以提供典型的管程风格的`await`、`signal`和`signalAll`操作，包括带有超时的，以及一些检测、监控的方法。\n\n通过修正一些设计决策，`ConditionObject`类有效地将条件（conditions）与其它同步操作结合到了一起。该类只支持 Java 风格的管程访问规则，这些规则中，仅当当前线程持有锁且要操作的条件（condition）属于该锁时，条件操作才是合法的（一些替代操作的讨论参考[[4\\]](http://ifeve.com/aqs-2/#r4)）。这样，一个`ConditionObject`关联到一个`ReentrantLock`上就表现的跟内置的管程（通过`Object.wait`等）一样了。两者的不同仅仅在于方法的名称、额外的功能以及用户可以为每个锁声明多个条件。\n\n`ConditionObject`使用了与同步器一样的内部队列节点。但是，是在一个单独的条件队列中维护这些节点的。`signal`操作是通过将节点从条件队列转移到锁队列中来实现的，而没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。\n\n基本的`await`操作如下：\n\n```\ncreate and add new node to conditon queue;release lock;block until node is on lock queue;re-acquire lock;\n```\n\n`signal`操作如下：\n\n```java\ntransfer the first node from condition queue to lock queue;\n```\n\n因为只有在持有锁的时候才能执行这些操作，因此他们可以使用顺序链表队列操作来维护条件队列（在节点中用一个`nextWaiter`字段）。转移操作仅仅把第一个节点从条件队列中的链接解除，然后通过 CLH 插入操作将其插入到锁队列上。\n\n实现这些操作主要复杂在，因超时或`Thread.interrupt`导致取消了条件等待时，该如何处理。“取消”和“唤醒”几乎同时发生就会有竞态问题，最终的结果遵照内置管程相关的规范。JSR133 修订以后，就要求如果中断发生在`signal`操作之前，await 方法必须在重新获取到锁后，抛出`InterruptedException`。但是，如果中断发生在`signal`后，`await`必须返回且不抛异常，同时设置线程的中断状态。\n\n为了维护适当的顺序，队列节点状态变量中的一个位记录了该节点是否已经（或正在）被转移。“唤醒”和“取消”相关的代码都会尝试用`compareAndSet`修改这个状态。如果某次`signal`操作修改失败，就会转移队列中的下一个节点（如果存在的话）。如果某次“取消”操作修改失败，就必须中止此次转移，然后等待重新获得锁。后面的情况采用了一个潜在的无限的自旋等待。在节点成功的被插到锁队列之前，被“取消”的等待不能重新获得锁，所以必须自旋等待 CLH 队列插入（即`compareAndSet`操作）被“唤醒”线程成功执行。这里极少需要自旋，且自旋里使用`Thread.yield`来提示应该调度某一其它线程，理想情况下就是执行 signal 的那个线程。虽然有可能在这里为“取消”实现一个帮助策略以帮助插入节点，但这种情况实在太少，找不到合适的理由来增加这些开销。在其它所有的情况下，这个基本的机制都不需要自旋或`yield`，因此在单处理器上保持着合理的性能。\n\n## 4 用法\n\nAQS 类将上述的功能结合到一起，并且作为一种基于“模版方法模式”[[6\\]](http://ifeve.com/aqs-3/#r6)的基类提供给同步器。子类只需定义状态的检查与更新相关的方法，这些方法控制着acquire和 release 操作。然而，将 AQS 的子类作为同步器 ADT 并不适合，因为这个类必须提供方法在内部控制 acquire 和 release 的规则，这些都不应该被用户所看到。所有 java.util.concurrent 包中的同步器类都声明了一个私有的继承了`AbstractQueuedSynchronizer`的内部类，并且把所有同步方法都委托给这个内部类。这样各个同步器类的公开方法就可以使用适合自己的名称。\n\n下面是一个最简单的`Mutex`类的实现，它使用同步状态 0 表示解锁，1 表示锁定。这个类并不需要同步方法中的参数，因此这里在调用的时候使用 0 作为实参，方法实现里将其忽略。\n\n```java\nclass Mutex {\tclass Sync extends AbstractQueuedSynchronizer {\t\tpublic boolean tryAcquire(int ignore) {\t\t\treturn compareAndSetState(0, 1);\t\t}\t\tpublic boolean tryRelease(int ignore) {\t\t\tsetState(0); return true;\t\t}\t}\tprivate final Sync sync = new Sync();\tpublic void lock() { sync.acquire(0); }\tpublic void unlock() { sync.release(0); }}\n```\n\n这个例子的一个更完整的版本，以及其它用法指南，可以在 J2SE 的文档中找到。还可以有一些变体。如，tryAcquire 可以使用一种“test-and-test-and-set”策略，即在改变状态值前先对状态进行校验。\n\n令人诧异的是，像互斥锁这样性能敏感的东西也打算通过委托和虚方法结合的方式来定义。然而，这正是现代动态编译器一直在重点研究的面向对象设计结构。编译器擅长将这方面的开销优化掉，起码会优化频繁调用同步器的那些代码。\n\n`AbstractQueuedSynchronizer`类也提供了一些方法用来协助策略控制。例如，基础的 acquire 方法有可超时和可中断的版本。虽然到目前为止，我们的讨论都集中在像锁这样的独占模式的同步器上，但`AbstractQueuedSynchronizer`类也包含另一组方法（如`acquireShared`），它们的不同点在于`tryAcquireShared`和`tryReleaseShared`方法能够告知框架（通过它们的返回值）尚能接受更多的请求，最终框架会通过级联的 signal(cascading signals)唤醒多个线程。\n\n虽然将同步器序列化（持久化存储或传输）一般来说没有太大意义，但这些类经常会被用于构造其它类，例如线程安全的集合，而这些集合通常是可序列化的。`AbstractQueuedSynchronizer`和`ConditionObject`类都提供了方法用于序列化同步状态，但不会序列化潜在的被阻塞的线程，也不会序列化其它内部暂时性的簿记（bookkeeping）变量。即使如此，在反序列化时，大部分同步器类也只仅将同步状态重置为初始值，这与内置锁的隐式策略一致 —— 总是反序列化到一个解锁状态。这相当于一个空操作，但仍必须显式地支持以便`final`字段能够反序列化。\n\n### 4.1 公平调度的控制\n\n尽管同步器是基于 FIFO 队列的，但它们并不一定就得是公平的。可以注意到，在基础的 acquire 算法（3.3 节）中，`tryAcquire`是在入队前被执行的。因此一个新的 acquire 线程能够“窃取”本该属于队列头部第一个线程通过同步器的机会。\n\n可*闯入*的 FIFO 策略通常会提供比其它技术更高的总吞吐率。当一个有竞争的锁已经空闲，而下一个准备获取锁的线程又正在解除阻塞的过程中，这时就没有线程可以获取到这个锁，如果使用*闯入*策略，则可减少这之间的时间间隔。与此同时，这种策略还可避免过分的，无效率的竞争，这种竞争是由于只允许一个（第一个）排队的线程被唤醒然后尝试 acquire 操作导致的。在只要求短时间持有同步器的场景中，创建同步器的开发者可以通过定义`tryAcquire`在控制权返回之前重复调用自己若干次，来进一步凸显*闯入*的效果。\n\n![img](https://cdn.wenzuo.net/assets/202109172035929.png)\n\n可闯入的 FIFO 同步器只有概率性的公平属性。锁队列头部一个解除了阻塞的线程拥有一次无偏向的机会（_译者注：即不会偏向队头的线程也不会偏向闯入的线程_）来赢得与*闯入*的线程之间的竞争，如果竞争失败，要么重新阻塞要么进行重试。然而，如果*闯入*的线程到达的速度比队头的线程解除阻塞快，那么在队列中的第一个线程将很难赢得竞争，以至于几乎总要重新阻塞，并且它的后继节点也会一直保持阻塞。对于短暂持有的同步器来说，在队列中第一个线程被解除阻塞期间，多处理器上很可能发生过多次*闯入*（_译者注：即闯入的线程的`acquire`操作_）和`release`了。正如下文所提到的，最终结果就是保持一或多个线程的高进展速度的同时，仍至少在一定概率上避免了饥饿的发生。\n\n当有更高的公平性需求时，实现起来也很简单。如果需要严格的公平性，程序员可以把 tryAcquire 方法定义为，若当前线程不是队列的头节点（可通过`getFirstQueuedThread`方法检查，这是框架提供的为数不多的几个检测方法之一），则立即失败（返回 false）。\n\n一个更快，但非严格公平的变体可以这样做，若队列为空（判断的瞬间），仍然允许`tryAcquire`执行成功。在这种情况下，多个线程同时遇到一个空队列时可能会去竞争以使自己第一个获得锁，这样，通常至少有一个线程是无需入队列的。`java.util.concurrent`包中所有支持公平模式的同步器都采用了这种策略。\n\n尽管公平性设置在实践中很有用，但是它们并没有保障，因为 Java Language Specification 没有提供这样的调度保证。例如：即使是严格公平的同步器，如果一组线程永远不需要阻塞来达到互相等待，那么 JVM 可能会决定纯粹以顺序方式运行它们。在实际中，单处理器上，在抢占式上下文切换之前，这样的线程有可能是各自运行了一段时间。如果这样一个线程正持有某个互斥锁，它将很快会被切换回来，仅是为了释放其持有的锁，然后会继续阻塞，因为它知道有另外一个线程需要这把锁，这更增加了同步器可用但没有线程能来获取之间的间隔。同步器公平性设置在多处理器上的影响可能会更大，因为在这种环境下会产生更多的交错，因此一个线程就会有更多的机会发现锁被另一个线程请求。\n\n在高竞争下，当保护的是短暂持有锁的代码体时，尽管性能可能会较差，但公平锁仍然能有效地工作。例如，当公平性锁保护的是相对长的代码体和/或有着相对长的锁间(inter-lock)间隔，在这种情况下，*闯入*只能带来很小的性能优势，但却可能会大大增加无限等待的风险。同步器框架将这些工程决策留给用户来确定。\n\n### 4.2 同步器\n\n下面是`java.util.concurrent`包中同步器定义方式的概述：\n\n`ReentrantLock`类使用 AQS 同步状态来保存锁（重复）持有的次数。当锁被一个线程获取时，`ReentrantLock`也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当错误的线程（_译者注：如果线程不是锁的持有者，在此线程中执行该锁的`unlock`操作就是非法的_）试图进行解锁操作时检测是否存在非法状态异常。`ReentrantLock`也使用了 AQS 提供的 ConditionObject，还向外暴露了其它监控和监测相关的方法。`ReentrantLock`通过在内部声明两个不同的`AbstractQueuedSynchronizer`实现类（提供公平模式的那个禁用了*闯入*策略）来实现可选的公平模式，在创建 ReentrantLock 实例的时候根据设置（_译者注：即`ReentrantLock`构造方法中的`fair`参数_）使用相应的`AbstractQueuedSynchronizer`实现类。\n\n`ReentrantReadWriteLock`类使用 AQS 同步状态中的 16 位来保存写锁持有的次数，剩下的 16 位用来保存读锁的持有次数。`WriteLock`的构建方式同`ReentrantLock`。`ReadLock`则通过使用`acquireShared`方法来支持同时允许多个读线程。\n\n`Semaphore`类（计数信号量）使用 AQS 同步状态来保存信号量的当前计数。它里面定义的 acquireShared 方法会减少计数，或当计数为非正值时阻塞线程；`tryRelease`方法会增加计数，可能在计数为正值时还要解除线程的阻塞。\n\n`CountDownLatch`类使用 AQS 同步状态来表示计数。当该计数为 0 时，所有的 acquire 操作（_译者注：acquire 操作是从 aqs 的角度说的，对应到`CountDownLatch`中就是`await`方法_）才能通过。\n\n`FutureTask`类使用 AQS 同步状态来表示某个异步计算任务的运行状态（初始化、运行中、被取消和完成）。设置（_译者注：`FutureTask`的`set`方法_）或取消（_译者注：`FutureTask`的`cancel`方法_）一个`FutureTask`时会调用 AQS 的`release`操作，等待计算结果的线程的阻塞解除是通过 AQS 的`acquire`操作实现的。\n\n`SynchronousQueues`类（一种 CSP*（Communicating Sequential Processes）*形式的传递）使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用 AQS 同步状态来控制当某个消费者消费当前一项时，允许一个生产者继续生产，反之亦然。\n\n`java.util.concurrent`包的使用者当然也可以为自定义的应用定义自己的同步器。例如，那些曾考虑到过的，但没有采纳进这个包的同步器包括提供 WIN32 事件各种风格的语义类，二元信号量，集中管理的锁以及基于树的屏障。\n\n## 5 性能\n\n虽然 AQS 框架除了支持互斥锁外，还支持其它形式的同步方式，但锁的性能是最容易测量和比较的。即使如此，也还存在许多不同的测量方式。这里的实验主要是设计来展示锁的开销和吞吐量。\n\n在每个测试中，所有线程都重复的更新一个伪随机数，该随机数由`nextRandom(int seed)`方法计算：\n\n```java\nint t = (seed % 127773) * 16807 - (seed / 127773) * 2836;return (t > 0) ? t : t + 0x7fffffff;\n```\n\n在每次迭代中，线程以概率 S 在一个互斥锁下更新共享的生成器，否则（_译者注：概率为 1-S_）更新其自己局部的生成器，此时是不需要锁的。如此，锁占用区域的耗时是短暂的，这就使线程持有锁期间被抢占时的外界干扰降到了最小。这个函数的随机性主要是为了两个目的：确定是否需要使用锁（这个生成器足以应付这里的需求），以及使循环中的代码不可能被轻易地优化掉。\n\n这里比较了四种锁：内置锁，用的是`synchronized`块；互斥锁，用的是像第四节例子中的那样简单的 Mutex 类；可重入锁，用的是`ReentrantLock`；以及公平锁，用的是`ReentrantLock`的公平模式。所有测试都运行在 J2SE1.5 JDK build46（大致与 beta2 相同）的 server 模式下。在收集测试数据前，测试程序先运行 20 次非竞争的测试，以排除 JVM“预热”（_译者注：更多关于“预热”的内容，参见：[Java 理论与实践: 动态编译与性能测量](http://www.ibm.com/developerworks/cn/java/j-jtp12214/#4.0)_）过程的影响。除了公平模式下的测试只跑了一百万次迭代，其它每个线程中的测试都运行了一千万次迭代。\n\n该测试运行在四个 X86 机器和四个 UltraSparc 机器上。所有 X86 机器都运行的是 RedHat 基于 NPTL 2.4 内核和库的 Linux 系统。所有的 UltraSparc 机器都运行的是 Solaris-9。测试时所有系统的负载都很轻。根据该测试的特征，并不要求系统完全空闲（_译者注：即测试时操作系统上有其它较轻的负载也不会影响本次测试的结果。_）。“4P”这个名字反映出双核超线程的 Xeon 更像是 4 路机器，而不是 2 路机器。这里没有将测试数据规范化。如下所示，同步的相对开销与处理器的数量、类型、速度之间不具备简单的关系。\n\n**表 1 测试的平台**\n\n| 名字 | 处理器数量 | 类型          | 速度(Mhz) |\n| ---- | ---------- | ------------- | --------- |\n| 1P   | 1          | Pentium3      | 900       |\n| 2P   | 2          | Pentium3      | 1400      |\n| 2A   | 2          | Athlon        | 2000      |\n| 4P   | 2HT        | Pentium4/Xeon | 2400      |\n| 1U   | 1          | UltraSparc2   | 650       |\n| 4U   | 4          | UltraSparc2   | 450       |\n| 8U   | 8          | UltraSparc3   | 750       |\n| 24U  | 24         | UltraSparc3   | 750       |\n\n### 5.1 开销\n\n无竞争情况下的开销是通过仅运行一个线程，将概率 S 为 1 时的每次迭代时间减去概率 S 为 0（访问共享内存的概率为 0）时的每次迭代时间得到的（_译者注：这里的“概率 S”即前文提到的“概率 S”，概率为 0 时是没有锁操作的，概率为 1 时是每次都有锁操作，因此将概率为 1 时的耗时减去概率为 0 时的耗时就是整个锁操作的开销。_）。表 2 以纳秒为单位显示了非竞争场景下每次锁操作的开销。Mutex 类最接近于框架的基本耗时，可重入锁的额外开销是记录当前所有者线程和错误检查的耗时，对于公平锁来说还包含开始时检查队列是否为空的耗时。\n\n表格 2 也展示与内置锁的“快速路径（fast path）”对比，`tryAcquire`的耗时。这里的差异主要反映出了各锁和机器中使用的不同的原子指令以及内存屏障的耗时。在多处理器上，这些指令常常是完全优于所有其它指令的。内置锁和同步器类之间的主要差别，显然是由于 Hotspot 锁在锁定和解锁时都使用了一次`compareAndSet`，而同步器的`acquire`操作使用了一次`compareAndSet`，但`release`操作用的是一次`volatile`写（即，多处理器上的一次内存屏障以及所有处理器上的重排序限制）。每个锁的绝对的和相对耗时因机器的不同而不同。\n\n**表 2 无竞争时的单锁开销（单位：纳秒）**\n\n| 机器 | 内置 | 互斥 | 可重入 | 公平可重入 |\n| ---- | ---- | ---- | ------ | ---------- |\n| 1P   | 18   | 9    | 31     | 37         |\n| 2P   | 58   | 71   | 77     | 81         |\n| 2A   | 13   | 21   | 31     | 30         |\n| 4P   | 116  | 95   | 109    | 117        |\n| 1U   | 90   | 40   | 58     | 67         |\n| 4U   | 122  | 82   | 100    | 115        |\n| 8U   | 160  | 83   | 103    | 123        |\n| 24U  | 161  | 84   | 108    | 119        |\n\n从另一个极端看，表 3 展示了概率 S 为 1，运行 256 个并发线程时产生了大规模的锁竞争下每个锁的开销。在完全饱和的情况下，可*闯入*的 FIFO 锁比内置锁的开销少了一个数量级（也就是更大的吞吐量），比公平锁更是少了两个数量级。这表现出即使有着极大的竞争，在维持线程进展方面可*闯入*FIFO 策略的效率。\n\n表 3 也说明了即使在内部开销比较低的情况下，公平锁的性能也完全是由上下文切换的时间所决定的。列出的时间大致上都与各平台上线程阻塞和解除线程阻塞的时间相称。\n\n此外，后面增加的一个实验（仅使用机器 4P）表明，对于这里用到的短暂持有的锁，公平参数的设置在总差异中的影响很小。这里将线程终止时间间的差异记录成一个粗粒度的离散量数。在 4P 的机器上，公平锁的时间度量的标准差平均为 0.7%，可重入锁平均为 6.0%。作为对比，为模拟一个长时间持有锁的场景，测试中使每个线程在持有锁的情况下计算了 16K 次随机数。这时，总运行时间几乎是相同的（公平锁：9.79s，可重入锁：9.72s）。公平模式下的差异依然很小，标准差平均为 0.1%，而可重入锁上升到了平均 29.5%。\n\n**表格 3 饱和时的单锁开销（单位：纳秒）**\n\n| 机器 | 内置 | 互斥 | 可重入 | 公平可重入 |\n| ---- | ---- | ---- | ------ | ---------- |\n| 1P   | 521  | 46   | 67     | 8327       |\n| 2P   | 930  | 108  | 132    | 14967      |\n| 2A   | 748  | 79   | 84     | 33910      |\n| 4P   | 1146 | 188  | 247    | 15328      |\n| 1U   | 879  | 153  | 177    | 41394      |\n| 4U   | 2590 | 347  | 368    | 30004      |\n| 8U   | 1274 | 157  | 174    | 31084      |\n| 24U  | 1983 | 160  | 182    | 32291      |\n\n### 5.2 吞吐量\n\n大部分同步器都是用于无竞争和极大竞争之间的。这可以用实验在两个方面进行检查，通过修改固定个线程的竞争概率，和/或通过往拥有固定竞争概率的线程集合里增加更多的线程。为了说明这些影响，测试运行在不同的竞争概率和不同的线程数目下，都用的是可重入锁。附图使用了一个*slowdown*度量标准。\n\n![img](https://cdn.wenzuo.net/assets/202109172037464.jpg)\n\n这里，t 是总运行时间，b 是一个线程在没有竞争或同步下的基线时间，n 是线程数，p 是处理器数，S 是共享访问的比例（_译者注：即前面的竞争概率 S_）。计算结果是实际执行时间与理想执行时间（通常是无法得到的）的比率，理想执行时间是通过使用 Amdahl’s 法则计算出来的。理想时间模拟了一次没有同步开销，没有因锁争用而导致线程阻塞的执行过程。即使这样，在很低的竞争下，相比理想时间，有一些测试结果却表现出了很小的速度增长，大概是由于基线和测试之间的优化、流水线等方面有着轻微的差别。\n\n图中用以 2 为底的对数为比例进行了缩放。例如，值为 1 表示实际时间是理想时间的两倍，4 表示慢 16 倍。使用对数就不需要依赖一个随意的基线时间（这里指的是计算随机数的时间），因此，基于不同底数计算的结果表现出的趋势应该是类似的。这些测试使用的竞争概率从 1/128（标识为“0.008”）到 1，以 2 的幂为步长，线程的数量从 1 到 1024，以 2 的幂的一半为步长。\n\n在单处理器（1P 和 1U）上，性能随着竞争的上升而下降，但不会随着线程数的增加而下降。多处理器在遭遇竞争时，性能下降的更快。根据多处理器相关的图表显示，开始出现的峰值处虽然只有几个线程的竞争，但相对性能通常却最差。这反映出了一个性能的*过渡区域*，在这里*闯入*的线程和被唤醒的线程都准备获取锁，这会让它们频繁的迫使对方阻塞。在大部分时候，过渡区域后面会紧接着一个*平滑区域*，因为此时几乎没有空闲的锁，所以会与单处理器上顺序执行的模式差不多；在多处理器机器上会较早进入平滑区域。例如，请注意，在满竞争（标识为“1.000”）下这些值表示，在处理器越少的机器上，会有更糟糕的相对速度下降。\n\n根据这些结果，可以针对阻塞（park/unpark）做进一步调优以减少上下文切换和相关的开销，这会给本框架带来小但显著的提升。此外，在多处理器上为短时间持有的但高竞争的锁采用某种形式的适应性自旋，可以避免这里看到的一些波动，这对同步器类大有裨益。虽然在跨不同上下文时适应性自旋很难很好的工作，但可以使用本框架为遇到这类使用配置的特定应用构建一个自定义形式的锁。\n\n![img](https://cdn.wenzuo.net/assets/202109172038612.jpg)\n\n![img](https://cdn.wenzuo.net/assets/202109172038850.jpg)\n\n![img](https://cdn.wenzuo.net/assets/202109172038797.jpg)\n\n![img](https://cdn.wenzuo.net/assets/202109172038674.jpg)\n\n## 6 总结\n\n本文撰写之时，`java.util.concurrent`包中的同步器框架还太新所以还不能在实践中使用。因此在 J2SE 1.5 最终版本发布之前都很难看到其大范围的使用，并且，它的设计，API 实现以及性能肯定还有无法预料的后果。但是，此时，这个框架明显能胜任其基本的目标，即为创建新的同步器提供一个高效的基础。\n\n## 7 致谢\n\nThanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.\n\n## 参考文献\n\n- [1] Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S.Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.\n- [2] Andrews, G. Concurrent Programming. Wiley, 1991.\n- [3] Bacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.\n- [4] Buhr, P. M. Fortier, and M. Coffin. Monitor Classification,ACM Computing Surveys, March 1995.\n- [5] Craig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02,Department of Computer Science, University of Washington, Feb. 1993.\n- [6] Gamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996.\n- [7] Holmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.\n- [8] Magnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.\n- [9] Mellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems,February 1991\n- [10] M. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.\n- [11] Sun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.\n- [12] Zhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.\n","tags":["Java","多线程"],"categories":["编程笔记"]},{"title":"为什么不建议使用Executors类创建线程池","url":"/posts/60517.html","content":"\n> `Executors` 是一个工具类，可以帮助我们快速创建线程池，但《阿里巴巴开发手册》却说不建议使用 `Executors` 来创建线程池，这是为什么呢？\n\n<!-- more -->\n\n## newFixedThreadPool\n\n由于传进去的 `LinkedBlockingQueue` 是一个无界队列，没有容量上限，所以当请求数越来越多，并且无法及时处理完的时候，就会不停的向 `LinkedBlockingQueue` 塞进线程，直至内存溢出 OOM\n\n## newSingleThreadExecutor\n\n这个和 `newFixedThreadPool` 的原理一样，只不过核心线程数和最大线程数都设置成了 1，但是由于同样使用了 `LinkedBlockingQueue`，所以也会因为大量线程堆积导致 OOM\n\n## newCachedThreadPool\n\n这个线程池使用了 `SynchronousQueue` 队列，这个队列可以理解为一个空队列，有任务进来，当前又没有空闲线程，那么就直接创建线程去执行，其特点是当一段时间没有任务进来，线程空置超过一定时间（默认是 60 s），线程就会回收。因为其最大线程数设置的值为 `Integer.MAX_VALUE` ，所以也会因为不断创建线程而导致 OOM\n\n## newScheduledThreadPool\n\n这是一个支持定时及周期性执行任务的线程池，其底层使用了 `DelayedWorkQueue` 其最大线程数也是 `Integer.MAX_VALUE`，同样有 OOM 的风险\n\n## 四种线程池的对比\n\n| 参数            | newFixedThreadPool              | newSingleThreadExecutor         | newCachedThreadPool            | newScheduledThreadPool       |\n| --------------- | ------------------------------- | ------------------------------- | ------------------------------ | ---------------------------- |\n| corePoolSize    | 参数指定                        | 1                               | 0                              | 参数指定                     |\n| maximumPoolSize | 等于 corePoolSize               | 1                               | Integer.MAX_VALUE              | Integer.MAX_VALUE            |\n| keepAliveTime   | 0s                              | 0s                              | 60s                            | 0s                           |\n| workQueue       | LinkedBlockingQueue（无界队列） | LinkedBlockingQueue（无界队列） | SynchronousQueue（无空间队列） | DelayedWorkQueue（无界队列） |\n\n## 正确创建线程池的方法\n\n我们应该根据不同的业务场景，自己设置线程池参数，比如我们的内存有多大，并发量有多大，想给线程取什么样的名字，线程异常如何处理\n","tags":["Java"],"categories":["编程笔记"]},{"title":"Semaphore的使用","url":"/posts/fdbf5aef.html","content":"\n## 概述\n\nSemaphore 是一个计数信号量，常用于限制可以访问某些资源（物理或逻辑的）线程数目。\n\n<!-- more -->\n\n## 方法\n\n### 构造方法\n\nSemaphore(int)、Semaphore(int,boolean)\n\nint 表示该信号量拥有的许可数量\n\nboolean 表示获取许可的时候是否是公平的。（公平指的是先来的先执行）\n\n### 获取许可\n\nacquire()、acquire(int)、tryAcquire()\n\nint 参数表示一次性要获取几个许可，默认为 1 个，acquire 方法在没有许可的情况下，要获取许可的线程会阻塞。\n\ntryAcquire()方法在没有许可的情况下会立即返回 false，要获取许可的线程不会阻塞。\n\n### 释放许可\n\nrelease()、release(int)\n\nint 参数表示一次性要释放几个许可，默认为 1 个，\n\n**注意：一个线程调用 release()之前并不要求一定要调用了 acquire 因此如果释放的比获取的信号量还多，例如获取了 2 个，释放了 5 次，那么当前信号量就动态的增加为 5 了（实现动态增加）**\n\n### 当前可用的许可数\n\nint availablePermits()\n\n## 使用\n\n```java\npackage org.example.concurrent;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Semaphore;\n\n/**\n * 常用于限流的应用场景\n * @author Catch\n * @since 2021/8/23 00:47\n */\npublic class SemaphoreCase {\n\n    // 线程池\n    private static final ExecutorService executorService = Executors.newCachedThreadPool();\n\n    // 只允许 2 个线程同时访问\n    private static final Semaphore semaphore = new Semaphore(2);\n\n    // 模拟20个客户端访问\n    public void doSomeThing(String threadName){\n        Runnable run = () -> {\n            try {\n                System.out.println( threadName + \"启动\");\n                // 获取许可\n                semaphore.acquire();\n                System.out.println(threadName + \"执行, 剩余许可数: \"+semaphore.availablePermits()+\">>>>>>>\");\n                //模拟实际业务逻辑\n                Thread.sleep((long) (Math.random() * 10000));\n                // 访问完后，释放\n                semaphore.release();\n                System.out.println(threadName + \"释放, 剩余许可数: \"+semaphore.availablePermits()+\"<<<<<<<\");\n            } catch (InterruptedException ignored) {\n            }\n        };\n        executorService.execute(run);\n    }\n\n    public static void main(String[] args) {\n        SemaphoreCase semaphoreCase=new SemaphoreCase();\n        for (int i = 0; i < 10; i++) {\n            semaphoreCase.doSomeThing(\"线程\"+i);\n        }\n    }\n}\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"IDEA 启动参数优化","url":"/posts/4ed78b9a.html","content":"\n## Idea2020 vmoptions 推荐(CMS 垃圾收集器)\n\n<!-- more -->\n\n```ini\n-ea\n-server\n-Xms1g\n-Xmx4g\n-Xss16m\n-XX:MetaspaceSize=1g\n-XX:MaxMetaspaceSize=2g\n-XX:ConcGCThreads=6\n-XX:ParallelGCThreads=6\n-XX:NewRatio=1\n-XX:ReservedCodeCacheSize=512m\n-XX:+AlwaysPreTouch\n-XX:+UseConcMarkSweepGC\n-XX:+DoEscapeAnalysis\n-XX:+TieredCompilation\n-XX:SoftRefLRUPolicyMSPerMB=50\n-XX:+UnlockExperimentalVMOptions\n-Djava.net.preferIPv4Stack=true\n-Dsun.io.useCanonCaches=false\n-XX:LargePageSizeInBytes=256m\n-XX:+UseCodeCacheFlushing\n-XX:+DisableExplicitGC\n-XX:+ExplicitGCInvokesConcurrent\n-XX:+PrintGCDetails\n-XX:+PrintFlagsFinal\n-XX:+AggressiveOpts\n-XX:+CMSClassUnloadingEnabled\n-XX:CMSInitiatingOccupancyFraction=60\n-XX:+CMSParallelRemarkEnabled\n-XX:+UseAdaptiveGCBoundary\n-XX:+UseSplitVerifier\n-XX:CompileThreshold=10000\n-XX:+OptimizeStringConcat\n-XX:+UseStringCache\n-XX:+UseFastAccessorMethods\n-XX:+UnlockDiagnosticVMOptions\n-Djdk.http.auth.tunneling.disabledSchemes=\"\"\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:+UseCompressedOops\n-XX:-OmitStackTraceInFastThrow\n-Dfile.encoding=UTF-8\n-Xverify:none\n\n-XX:ErrorFile=/Users/zhanghao/logs/idea/idea2020_error_%p.log\n-XX:HeapDumpPath=/Users/zhanghao/logs/idea/idea2020_error.hprof\n\n```\n\n## Idea2021 vmoptions 推荐(G1 垃圾收集器)\n\n```ini\n-ea\n-server\n-Xms1g\n-Xmx4g\n-Xss16m\n-XX:MetaspaceSize=1g\n-XX:MaxMetaspaceSize=2g\n-XX:ConcGCThreads=6\n-XX:ParallelGCThreads=6\n-XX:NewRatio=1\n-XX:ReservedCodeCacheSize=512m\n-XX:+AlwaysPreTouch\n-XX:+UseG1GC\n-XX:+DoEscapeAnalysis\n-XX:+TieredCompilationUseG1GC\n-XX:SoftRefLRUPolicyMSPerMB=50\n-XX:+UnlockExperimentalVMOptions\n-Dsun.io.useCanonPrefixCache=false\n-Djava.net.preferIPv4Stack=true\n-Dsun.io.useCanonCaches=false\n-XX:LargePageSizeInBytes=256m\n-XX:+UseCodeCacheFlushing\n-XX:+DisableExplicitGC\n-XX:+ExplicitGCInvokesConcurrent\n-XX:+PrintGCDetails\n-XX:+PrintFlagsFinal\n-XX:+AggressiveOpts\n-XX:+CMSClassUnloadingEnabled\n-XX:CMSInitiatingOccupancyFraction=60\n-XX:+CMSParallelRemarkEnabled\n-XX:+UseAdaptiveGCBoundary\n-XX:+UseSplitVerifier\n-XX:CompileThreshold=10000\n-XX:+OptimizeStringConcat\n-XX:+UseStringCache\n-XX:+UseFastAccessorMethods\n-XX:+UnlockDiagnosticVMOptions\n-Djdk.http.auth.tunneling.disabledSchemes=\"\"\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:-OmitStackTraceInFastThrow\n-Djdk.attach.allowAttachSelf=true\n-Dkotlinx.coroutines.debug=off\n-Djdk.module.illegalAccess.silent=true\n-XX:+UseCompressedOops\n-Dfile.encoding=UTF-8\n-Xverify:none\n-XX:CICompilerCount=2\n\n-XX:ErrorFile=/Users/zhanghao/logs/idea/idea2021_error_%p.log\n-XX:HeapDumpPath=/Users/zhanghao/logs/idea/idea2021_error.hprof\n\n```\n","tags":["idea"],"categories":["工具配置"]},{"title":"Redis 基础数据结构","url":"/posts/3909088b.html","content":"\nRedis 有 5 种基础数据结构，分别为:string (字符串)、list (列表)、set (集合)、hash (哈 希) 和 zset (有序集合)。\n\n<!-- more -->\n\n## string 字符串\n\n字符串 string 是 Redis 最简单的数据结构。\n\nRedis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，内部为当前字 符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时， 扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是 字符串最大长度为 512M。\n\n![](http://cdn.wenzuo.net/catch6-github-io/20210509013317.png)\n\n### 常用操作\n\n```sh\n# 键值操作\nset key value\nget key\nexists key\ndel key\n\n# 批量键值操作\nmget key1 key2 key3\nmset key1 value1 key2 value2 key3 value3\n\n# 过期和 set 指令扩展\nexpire key 5 # 5秒后过期\nsetex key 5 value # 5秒后过期 等价于set+expire\nsetnx key value # 如果 key 不存在，则执行 set 创建并返回 1，key 存在则创建失败并返回0\n\n# 计数\n# 如果 value 的值是一个整数，还可以进行自增操作。自增的范围为 long 的最大和最小值\nset age 15\nincr age\nincrby age 5 # 自增步长为 5，15+5=20\nincrby age -5 # 相当于自减步长为5，20-5=15\n# 自减\ndecr age\ndecrby age 5\n```\n\n## list 列表\n\nRedis 里的列表相当于 Java 的 LinkedList，注意它是链表不是数组，所以插入和删除的速度非常快 O(1), 但是索引定位很慢 O(n)\n\n当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。\n\nRedis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符 串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。\n\n队列: 先进先出\n\n```sh\n# 从右边进，左边出\nrpush books python java golang\nlpop books\n\n# 从左边进，右边出\nlpush books python java golang\nrpop books\n```\n\n栈: 先进后出\n\n```sh\nrpush books python java golang\nrpop books\n\nlpush books python java golang\nlpop books\n```\n\n### 慢操作\n\n**lindex 相当于 Java 链表的 get(int index)方法，它需要对链表进行遍历，性能随着参数 index 增大而变差。 谨慎使用！除此之外还有 lrange, ltrim**\n\n```sh\n# O(n) 慎用\nlindex books 1\n\n# O(n) 慎用\n# 获取所有元素, -1是最后一个元素, [0,-1]\nlrange books 0 -1\n\n# O(n) 慎用\n# 保留 第 2 个元素到最后一个元素,即之外的元素都砍掉, [1,-1]\nltrim books 1 -1\n```\n\n## hash 字典\n\nRedis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞 时，就会将碰撞的元素使用链表串接起来。\n\n![](https://cdn.wenzuo.net/catch6-github-io/20210520195133.png)\n\n不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。\n\n渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容 一点点迁移到新的 hash 结构中。\n\n当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。\n\nhash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符 串，需要根据实际情况再三权衡。\n\n```sh\nhset books java \"thinking in java\"\nhget books java\nhlen books\n```\n\n## set 集合\n\nRedis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的 内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。\n\n当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。 set 结构可以用来 存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。\n\n```sh\nsadd books java\nsadd books go python\n\n# 获取所有元素, 注意和插入的顺序不一定一致,因为 set 是无序的\nsmembers books\n\n# 查询某个元素是否存在\nsismember books java\n\n# 查询长度, 相当于 count\nscard books\n\n# 弹出一个\nspop books\n```\n\n## zset 有序列表\n\nzset 类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权 重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。\n\nzset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。\n\nzset 可以用来存 粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间 进行排序。\nzset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们 可以对成绩按分数进行排序就可以得到他的名次。\n\n```sh\nzadd books 9.0 \"think in java\"\nzadd books 8.9 \"java concurrency\"\n\n# 按 score 排序列出，参数区间为排名范围\nzrange books 0 -1\n# 按 score 逆序列出，参数区间为排名范围\nzrevrange books 0 -1\n\n# 相当于 count()\nzcard books\n\n# 获取指定 value 的 score\n# 内部 score 使用 double 类型进行存储，所以存在小数点精度问题\nzscore books \"java concurrency\"\n\n# 排名\nzrank books \"java concurrency\"\n\n# 根据分值区间遍历 zset\nzrangebyscore books 0 8.91\n\n# 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。\nzrangebyscore books -inf 8.91 withscores\n\n# 删除 value\nzrem books \"java concurrency\"\n```\n","tags":["Redis"],"categories":["编程笔记"]},{"title":"ElasticSearch 基本概念","url":"/posts/df79f51.html","content":"\n## 概述\n\nElasticsearch 是一个基于 Lucene 的实时的分布式搜索和分析引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。基于 RESTful 接口\n\n<!-- more -->\n\n## 核心概念\n\n- 集群（Cluster）： ES 是一个分布式的搜索引擎，一般由多台物理机组成。这些物理机，通过配置一个相同的 cluster name，互相发现，把自己组织成一个集群。\n- 节点（Node)：同一个集群中的一个 Elasticearch 主机。\n- 主分片（Primary shard）：索引（下文介绍）的一个物理子集。同一个索引在物理上可以切多个分片，分布到不同的节点上。分片的实现是 Lucene 中的索引。\n- 注意：ES 中一个索引的分片个数是建立索引时就要指定的，建立后不可再改变。所以开始建一个索引时，就要预计数据规模，将分片的个数分配在一个合理的范围。\n- 副本分片（Replica shard）：每个主分片可以有一个或者多个副本，个数是用户自己配置的。ES 会尽量将同一索引的不同分片分布到不同的节点上，提高容错性。对一个索引，只要不是所有 shards 所在的机器都挂了，就还能用。\n- 索引（Index)：逻辑概念，一个可检索的文档对象的集合。类似与 DB 中的 database 概念。同一个集群中可建立多个索引。比如，生产环境常见的一种方法，对每个月产生的数据建索引，以保证单个索引的量级可控。\n- 类型（Type）：索引的下一级概念，大概相当于数据库中的 table。同一个索引里可以包含多个 Type。\n- 文档（Document)：即搜索引擎中的文档概念，也是 ES 中一个可以被检索的基本单位，相当于数据库中的 row，一条记录。\n- 字段（Field）：相当于数据库中的 column。ES 中，每个文档，其实是以 json 形式存储的。而一个文档可以被视为多个字段的集合。比如一篇文章，可能包括了主题、摘要、正文、作者、时间等信息，每个信息都是一个字段，最后被整合成一个 json 串，落地到磁盘。\n- 映射（Mapping）：相当于数据库中的 schema，用来约束字段的类型，不过 Elasticsearch 的 mapping 可以不显示地指定、自动根据文档数据创建。\n\nElasticsearch 集群可以包含多个索引（indices），每一个索引可以包含多个类型（types），每一个类型包含多个文档（documents），然后每个文档包含多个字段（Fields），这种面向文档型的储存，也算是 NoSQL 的一种吧。\n\n## ES 比传统关系型数据库，对一些概念上的理解：\n\nRelational DB -> Databases -> Tables -> Rows -> Columns\nElasticsearch -> Indices -> Types -> Documents -> Fields\n","tags":["Java","ElasticSearch"],"categories":["编程笔记"]},{"title":"ElasticSearch 基本操作","url":"/posts/4d132828.html","content":"\n## matchQuery\n\n简单的 matchQuery 查询的内容会通过分词，分词后的数据进行检索，只要包含其中一个分词就会被检索出来\n\n<!-- more -->\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.matchQuery(\"fieldD\", \"bigData is magic\"));\n```\n\n## matchPhraseQuery\n\nmatchPhraseQuery 查询的内容通过分词，严格按照分词的出现的顺序进行查询，也就是必须包含所有分词，且出现数据的顺序一致\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.matchPhraseQuery(\"fieldD\", \"bigData spark is  magic\"));\n```\n\n查询的字段是进行分词索引的，如果不是分词索引则不生效, 如果只是查询 bigData magic ，则这种查询是查询不到的，需要完全匹配,如果想要查询到，需要设置 slop(2),需要这样查询\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.matchPhraseQuery(\"fieldD\", \"bigData spark is magic\").slop(2))\n```\n\n## termQuery\n\ntermQuery 词精确查询，fieldD 分词后包含 bigData 的 term 的文档\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.termQuery(\"fieldD\", \"bigData\"));\n```\n\n## termsQuery\n\ntermsQuery 多 term 查询，查询 fieldD 包含 bigData spark 或 storm 中的任何一个或多个的文档\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.termsQuery(\"fieldD\", \"bigData\",\"spark\",\"storm\"));\n```\n\n## rangeQuery\n\nrangeQuery 范围查询字段 fieldB 大于 20 并且小于 50 包含上下界\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.rangeQuery(\"filedB\").gt(\"20\").lt(\"50\").includeLower(true).includeUpper(true));\n```\n\n## prefixQuery\n\nprefixQuery 匹配分词前缀 如果字段没分词，就匹配整个字段前缀\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.prefixQuery(\"fieldD\",\"spark\"));\n```\n\n## wildcardQuery\n\nwildcardQuery 通配符查询，支持\\* 任意字符串；？任意一个字符\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.wildcardQuery(\"fieldD\",\"spark*\"));\n```\n\n## fuzzyQuery\n\nfuzzyQuery 分词模糊查询，通过增加 fuzziness 模糊属性，来查询 term 如下 能够匹配 fieldD 为 spar park spark 前或后加一个字母的 term 的 文档 fuzziness 的含义是检索的 term 前后增加或减少 n 个单词的匹配查询\n\n```java\nsearchRequestBuilder.setQuery(QueryBuilders.fuzzyQuery(\"fieldD\",\"spark\").fuzziness(Fuzziness.ONE));\n```\n","tags":["Java","ElasticSearch"],"categories":["编程笔记"]},{"title":"iterm2 快捷键","url":"/posts/6eb494d9.html","content":"\n## 标签\n\n```plain\n新建标签：command + t\n\n关闭标签：command + w\n\n切换标签：command + 数字 command + 左右方向键\n\n切换全屏：command + enter\n\n查找：command + f\n```\n\n<!-- more -->\n\n## 分屏\n\n```plain\n垂直分屏：command + d\n\n水平分屏：command + shift + d\n\n切换屏幕：command + option + 方向键 command + [ 或 command + ]\n\n查看历史命令：command + ;\n\n查看剪贴板历史：command + shift + h\n```\n\n## 其他\n\n```plain\n清除当前行：ctrl + u\n\n到行首：ctrl + a\n\n到行尾：ctrl + e\n\n前进后退：ctrl + f/b (相当于左右方向键)\n\n上一条命令：ctrl + p\n\n搜索命令历史：ctrl + r\n\n删除当前光标的字符：ctrl + d\n\n删除光标之前的字符：ctrl + h\n\n删除光标之前的单词：ctrl + w\n\n删除到文本末尾：ctrl + k\n\n交换光标处文本：ctrl + t\n\n清屏1：command + r\n\n清屏2：ctrl + l\n\n自带有哪些很实用的功能/快捷键\n\n⌘ + 数字在各 tab 标签直接来回切换\n\n选择即复制 + 鼠标中键粘贴，这个很实用\n\n⌘ + f 所查找的内容会被自动复制\n\n⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏\n\n⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏\n\nctrl + u 清空当前行，无论光标在什么位置\n\n输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令\n\n⌘ + shift + h 会列出剪切板历史\n\n可以在 Preferences > keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现\n```\n\n## 常用的一些快捷键\n\n```plain\n⌘ + 1 / 2 左右 tab 之间来回切换，这个在 前面 已经介绍过了\n\n⌘← / ⌘→ 到一行命令最左边/最右边 ，这个功能同 C+a / C+e\n\n⌥← / ⌥→ 按单词前移/后移，相当与 C+f / C+b，其实这个功能在Iterm中已经预定义好了，⌥f / ⌥b，看个人习惯了\n\n好像就这几个\n\n设置方法如下\n\n当然除了这些可以自定义的也不能忘了 linux 下那些好用的组合\n\nC+a / C+e 这个几乎在哪都可以使用\n\nC+p / !! 上一条命令\n\nC+k 从光标处删至命令行尾 (本来 C+u 是删至命令行首，但iterm中是删掉整行)\n\nC+w A+d 从光标处删至字首/尾\n\nC+h C+d 删掉光标前后的自负\n\nC+y 粘贴至光标后\n\nC+r 搜索命令历史，这个较常用\n```\n","tags":["Mac"],"categories":["编程笔记"]},{"title":"SpringBoot获取Request和Response","url":"/posts/4e6457e2.html","content":"\n使用 Springboot，我们很多时候直接使用@PathVariable、@RequestParam、@Param 来获取参数，但是偶尔还是要用到 request 和 response，怎么获取呢？\n\n<!-- more -->\n\n有三种方式可以获取, 任选其一就行, 建议第三种\n\n## 通过静态方法获取\n\n此方法可避免 aop 对 response.getWriter() 的调用, 导致流被打开\n\n```java\n@GetMapping(value = \"\")\npublic String center() {\n    ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();\n    HttpServletRequest request = servletRequestAttributes.getRequest();\n    HttpServletResponse response = servletRequestAttributes.getResponse();\n    //...\n}\n```\n\n## 通过绑定参数获取\n\n使用此方法 SpringBoot 会帮你做参数绑定\n\n```java\n@GetMapping(value = \"\")\npublic String center(HttpServletRequest request,HttpServletResponse response) {\n    //...\n}\n```\n\n## 注入到类中\n\n```java\n@Autowired\nprivate HttpServletRequest request;\n\n@Autowired\nprivate HttpServletResponse response;\n\n@GetMapping(value = \"\")\npublic String center() {\n    //...\n}\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"操作日志工具类 Diff","url":"/posts/caa5f707.html","content":"\n## 概述\n\n业务上经常会需要记录某些数据的操作明细, 出现事故可以追查到是谁于什么时间修改或删除了数据, 这就需要这些字段逐个进行 diff 记录, 下面是一个工具类\n\n<!-- more -->\n\n## Diff 类\n\n```java\npackage com.abc.utils;\n\nimport lombok.Data;\n\n/**\n * @author Catch\n * @since 2021/3/4 11:45\n */\n@Data\npublic class Diff {\n\n    private String template = \"[%s]: %s -> %s\\n\";\n    private StringBuilder content = new StringBuilder();\n\n\n    public static Diff builder() {\n        return new Diff();\n    }\n\n    public String build() {\n        return this.getContent().toString();\n    }\n\n    public Diff diffField(String fieldName, String before, String after) {\n        // 处理 before 或 after 可能为 null 的情况, 并去除空格\n        before = (before == null || \"null\".equals(before)) ? \"\" : before.trim();\n        after = (after == null || \"null\".equals(after)) ? \"\" : after.trim();\n\n        if (before.equals(after)) {\n            return this;\n        }\n        this.getContent().append(String.format(template, fieldName, before, after));\n        return this;\n    }\n\n}\n```\n\n## 使用\n\n```java\npackage com.abc.utils;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport org.junit.Test;\n\n/**\n * @author Catch\n * @since 2021/3/4 12:12\n */\npublic class DiffTest {\n\n    @Test\n    public void testDiff() {\n        User before = new User(1L, \"李明\", 1, 19, \"\");\n        User after = new User(1L, \"李华\", null, 20, \"工程师\");\n\n        String operations = Diff.builder()\n                .diffField(\"姓名\", before.getName(), after.getName())\n                .diffField(\"性别\", formatGender(before.getGender()), formatGender(after.getGender()))\n                .diffField(\"年龄\", String.valueOf(before.getAge()), String.valueOf(after.getAge()))\n                .diffField(\"职位\", before.getPosition(), after.getPosition())\n                .build();\n\n        System.out.println(operations);\n    }\n\n    public String formatGender(Integer gender) {\n        if (gender == null) {\n            return null;\n        }\n        return gender == 1 ? \"男\" : \"女\";\n    }\n\n    @Data\n    @AllArgsConstructor\n    public static class User {\n\n        private Long id;\n        private String name;\n        private Integer gender;\n        private Integer age;\n        private String position;\n\n    }\n\n}\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"线上问题诊断工具Arthas","url":"/posts/5ef0cd11.html","content":"\n## 是什么\n\nArthas 是 Alibaba 开源的 Java 诊断工具\n\n## 能解决什么问题\n\n1. 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？\n2. 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？\n3. 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？\n4. 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！\n5. 是否有一个全局视角来查看系统的运行状况？\n6. 有什么办法可以监控到 JVM 的实时运行状态？\n7. 怎么快速定位应用的热点，生成火焰图？\n\n<!-- more -->\n\n## 如何使用\n\n### 安装\n\n首先启动你的 java 应用程序, 这一点要注意\n\n```sh\ncurl -O https://arthas.aliyun.com/arthas-boot.jar\n\njava -jar arthas-boot.jar\n\n# 如果下载速度慢可以使用 aliyun 镜像\njava -jar arthas-boot.jar --repo-mirror aliyun --use-http\n```\n\n运行上面命令会让你选择代理的应用, 输入应用前面的序号并回车, 开始下载 arthas, 可以看到 arthas 下载到了 `/Users/zhanghao/.arthas/lib/3.4.6/arthas` 下, 日志会存储在 `/Users/zhanghao/logs`\n\n![](https://cdn.wenzuo.net/assets/202201101204166.png)\n","tags":["Java","Arthas"],"categories":["编程笔记"]},{"title":"SpringBoot异步线程池","url":"/posts/608b95b5.html","content":"\n## 概述\n\n在实际开发中，大多数请求都是同步执行，但有的时候请求中的某个操作可能会非常耗时，我们通常会采用异步操作，下面讲解如何在 Spring 中使用异步线程池\n\n<!-- more -->\n\n## 在 Spring 中开启异步线程池\n\n在 Spring 中存在一个 AsyncConfigurer 接口，它是一个可以配置异步线程池的接口，它的源码如代码\n\n```java\npackage org.springframework.scheduling.annotation;\n/**** imports ****/\npublic interface AsyncConfigurer {\n\n    // 获取线程池\n    @Nullable\n    default Executor getAsyncExecutor() {\n        return null;\n    }\n\n    // 异步异常处理器\n    @Nullable\n    default AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {\n        return null;\n    }\n}\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"Mac 上 Microsoft Autoupdate 问题解决","url":"/posts/93e2a907.html","content":"\n<!-- more -->\n\n## 提示[更新已在进行中，请稍后再试]\n\n1. 打开活动监视器\n2. 找到 `mircosoft autoupdate assistant` 的进程, 关闭这个进程\n3. 再次点击更新即可\n\n## 一直停留在正在安装状态\n\n打开 iterm2, 输入以下命令打印下载的安装包所在文件夹\n\n```sh\nfind /private/var/folders -iname \"*.pkg\" 2&>/dev/null\n```\n\n使用 finder 打开该目录,双击安装即可\n","tags":["Java"],"categories":["编程笔记"]},{"title":"Mybatis 的常用技巧","url":"/posts/b9565191.html","content":"\n<!-- more -->\n\n## 多条记录合并为一行\n\n假如有表 stu, 有 name 列如下\n\n| name |\n| ---- |\n| 小明 |\n| 小李 |\n| 小米 |\n\n现在要把 name 列拼接为一行, 如 `小明,小李,小米`, 可以使用如下 sql\n\n```sql\nSELECT GROUP_CONCAT(name SEPARATOR ',') AS names FROM stu;\n```\n\n## 批量插入\n\n```xml\n<insert id=\"batchInsert\" parameterType=\"com.xxx.UserDTO\"\n        useGeneratedKeys=\"true\" keyProperty=\"id\">\n    INSERT INTO t_user\n    (name, parent_name, create_time)\n    VALUES\n    <foreach collection=\"list\" item=\"item\" separator=\",\">\n        (#{item.name}, #{item.parentName}, now())\n    </foreach>\n</insert>\n```\n\n## 批量更新\n\n```xml\n<update id=\"batchUpdate\" parameterType=\"com.xxx.UserDTO\">\n    UPDATE t_user\n    <trim prefix=\"set\" suffixOverrides=\",\">\n        <trim prefix=\"name =case\" suffix=\"end,\">\n            <foreach collection=\"list\" item=\"item\">\n                <if test=\"item.name !=null\">\n                    when id=#{item.id} then #{item.name}\n                </if>\n            </foreach>\n        </trim>\n        <trim prefix=\"parent_name =case\" suffix=\"end,\">\n            <foreach collection=\"list\" item=\"item\">\n                <if test=\"item.parentName !=null\">\n                    when id=#{item.id} then #{item.parentName}\n                </if>\n            </foreach>\n        </trim>\n    </trim>\n    where id in\n    <foreach collection=\"list\" item=\"item\" separator=\",\" open=\"(\" close=\")\">\n        #{item.id}\n    </foreach>\n</update>\n```\n\n## in() 有序查询\n\n```xml\n<select id=\"findByIdsWithSorted\" parameterType=\"java.lang.Long\" resultType=\"com.xxx.UserDTO\">\n    SELECT *\n    from t_user WHERE id IN\n    <foreach collection=\"list\" item=\"item\" open=\"(\" close=\")\" separator=\",\">\n        #{item}\n    </foreach>\n    <foreach collection=\"list\" item=\"item\" open=\"order by field(id,\" close=\")\" separator=\",\">\n        #{item}\n    </foreach>\n</select>\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"Mysql 配置参数优化","url":"/posts/ffb836f.html","content":"\n<!-- more -->\n\n## 优化最大连接数\n\n`max_connections` 是 MySQL 最大并发连接数，默认值是 151\nMySQL 允许的最大连接数上限是 16384\n实际连接数是最大连接数的 85% 较为合适\n\n查询数据库目前设置的最大并发连接数是多少?\n\n```sql\nSHOW VARIABLES LIKE 'max_connections';\n```\n\n查询数据库目前实际连接的并发数是多少\n\n```sql\nSHOW STATUS LIKE 'max_used_connections';\n```\n\n在 MySQL 配置文件 `/etc/my.cnf` 中设置 `max_connections=3000`，表示修改最大连接数为 3000，需要重启 MySQL 才能生效\n\nMySQL 为每个连接创建缓冲区，所以不应该盲目上调最大连接数，如果最大连接数达到了上面设置的 3000，会消耗大约 800M 内存。\n\n## 优化请求堆栈\n\nback_log 是存放执行请求的堆栈大小，默认值是 50\n该值设置为最大并发连接数的 20%～ 30% 较为合适\n同样是在 MySQL 配置文件 `/etc/my.cnf` 中，设置 `back_log=600`，修改后需要重启 MySQL 才能生效\n\n## 修改并发线程数\n\n`innodb_thread_concurrency` 代表并发线程数，默认是 0，表示没有设置线程数量的上限。\n不是分配给 MySQL 的线程越多越好，线程多反而会损耗 cpu 性能，导致速度变慢\n并发线程数应该设置为 cpu 核心数的两倍\n\n在 MySQL 配置文件 `/etc/my.cnf` 中，设置 `innodb_thread_concurrency=8`\n\n查看 cpu 型号\n\n```sh\ncat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c\n```\n\n查看 cpu 核心数\n\n```sh\ncat /proc/cpuinfo | grep \"cores\"|uniq\n```\n\n## 修改连接超时时间\n\n`wait-timeout` 是超时时间，单位是秒\n连接默认超时为 8 小时，连接长期不用又不销毁，浪费资源\n设置超时时间为 10 分钟 `wait-timeout=600`\n\n## InnoDB 缓存\n\n修改 InnoDB 缓存大小\n\n`innodb_buffer_pool_size` 是 InnoDB 的缓存容量，默认是 128M\n\nInnoDB 缓存的大小可以设置为主机内存的 70%～ 80%\n\n在 MySQL 配置文件中，会有一行被注释的配置：`# innodb_buffer_pool_size = 128M`\n\n上方注释也写明了，建议设置物理内存的 70%\n\n```sh\n# Remove leading # and set to the amount of RAM for the most important data\n# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.\n# innodb_buffer_pool_size = 128M\n```\n","tags":["Mysql"],"categories":["编程笔记"]},{"title":"oh-my-zsh国内镜像安装和更新方法","url":"/posts/b33acd9a.html","content":"\n## 下载码云安装包\n\n```sh\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh\n```\n\n<!-- more -->\n\n## 编辑 install.sh\n\n找到以下部分\n\n```sh\n# Default settings\nZSH=${ZSH:-~/.oh-my-zsh}\nREPO=${REPO:-ohmyzsh/ohmyzsh}\nREMOTE=${REMOTE:-https://github.com/${REPO}.git}\nBRANCH=${BRANCH:-master}\n```\n\n把\n\n```sh\nREPO=${REPO:-ohmyzsh/ohmyzsh}\nREMOTE=${REMOTE:-https://github.com/${REPO}.git}\n```\n\n替换为\n\n```sh\nREPO=${REPO:-mirrors/oh-my-zsh}\nREMOTE=${REMOTE:-https://gitee.com/${REPO}.git}\n```\n\n编辑后保存, 运行安装即可. (运行前先给 `install.sh` 权限 `chmod +x install.sh`)\n\n## 修改仓库地址\n\n```sh\ncd ~/.oh-my-zsh\ngit remote set-url origin https://gitee.com/mirrors/oh-my-zsh.git\ngit pull\n```\n\n原文链接: https://touka.dev/tech/oh-my-zsh-china-mirror/\n","tags":["Linux"],"categories":["编程笔记"]},{"title":"Linux按日期备份命令","url":"/posts/944c70de.html","content":"\n<!-- more -->\n\n```sh\n# 把 nginx.conf 及 sites-available, sites-enabled 目录压缩以日期结尾备份\ntar -czvf nginx_$(date +'%F_%H-%M-%S').tar.gz nginx.conf sites-available/ sites-enabled/\n```\n","tags":["Linux"],"categories":["编程笔记"]},{"title":"Docker微容器 Alpine Linux","url":"/posts/952740e4.html","content":"\n## 简介\n\n使用 Docker 创建容器时，基础镜像通常选择 Ubuntu 或 Centos，不管哪个镜像的大小都在 100MB 以上。\n\nAlpine Linux 是一个面向安全的轻型的 Linux 发行版。\n\nAlpine Linux 采用了 [musl libc](http://busybox.net/) 和 [busybox](http://busybox.net/) 以减小系统的体积和运行时资源消耗。\n\n在保持瘦身的同时，Alpine Linux 还提供了自己的包管理工具 apk。\n\n关键的是，相比于其他 Linux 的 Docker 镜像，它的容量非常小，仅仅只有 5MB。\n\nAlpine Linux 的官网：\n\nhttp://www.alpinelinux.org/\n\nhttps://pkgs.alpinelinux.org/packages\n\n<!-- more -->\n\n## 下面使用 Alpine 镜像，来制作 nginx 容器。\n\n### 制作 Dockerfile\n\n```sh\n# vim Dockerfile\n\nFROM alpine:latest\nMAINTAINER zhanghao zhanghao@wenzuo.net\n\n# 下面指令可替换软件源为清华镜像源, 并更新软件包缓存, 然后安装 nginx\nRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories \\\n&& apk --update add nginx\n\nEXPOSE 80\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### 用 Dockerfile 创建镜像\n\n```sh\ndocker build -t zhanghao/nginx .\n```\n\n### 用创建好的镜像启动容器\n\n确认镜像信息\n\n```sh\ndocker images\n```\n\nAlpine 的镜像不到 5MB，用 Alpine 作为基础镜像的 nginx 镜像不到 7MB。\n\n启动容器\n\n```sh\ndocker run --name my-alpine-nginx -d -p 80:80 zhanghao/nginx\n```\n\n## 问题点\n\n1. Alpine Linux 使用了 musl，可能和其他 Linux 发行版使用的 glibc 实现会有些不同。\n2. musl 实现的 DNS 服务不会使用 resolv.conf 文件中的 search 和 domain 两个配置，通过 DNS 来进行服务发现时需要注意。\n\n## 后记\n\nAlpine Linux 的最大优势是小，有消息说 Docker 官方镜像将会使用 Alpine Linux 替换 Ubuntu。\n","tags":["Docker"],"categories":["编程笔记"]},{"title":"Springboot 使用 Docker 部署","url":"/posts/3a973f0f.html","content":"\n![](https://cdn.wenzuo.net/assets/202201101204385.png)\n","tags":["SpringBoot","Docker"],"categories":["编程笔记"]},{"title":"Docker 远程安全访问","url":"/posts/e81d826e.html","content":"\n## 直接设置任意远程访问存在的问题\n\n因为 docker 默认是 root 权限，允许所有人访问，直接把 2375 端口暴露在外网相当于直接把服务器的 root 权限拱手送人，因此我们需要构建一个加密的 TCP 链接，以 Https 的方式连接到远程的 docker 服务器\n\n<!-- more -->\n\n## 创建一个 ca 的文件夹\n\n```sh\nmkdir -p /usr/local/ca\ncd /usr/local/ca\n```\n\n## 创建一个 key\n\n```sh\nopenssl genrsa -aes256 -out ca-key.pem 4096\n```\n\n提示你需要输入密码和确认密码，**请记住这个密码**\n\n## 填写一些基本的信息，国家啊，地区什么的\n\n```sh\n# 执行这一句需要输入之前设置的密码\nopenssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem\n```\n\n我填写的内容如下\n\n```plain\nCountry Name (2 letter code) [AU]:CN\nState or Province Name (full name) [Some-State]:Beijing\nLocality Name (eg, city) []:Beijing\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:wenzuo\nOrganizational Unit Name (eg, section) []:wenzuo\nCommon Name (e.g. server FQDN or YOUR name) []:wenzuo\nEmail Address []:zhanghao@wenzuo.net\n```\n\n## 生成 server-key.pem\n\n```sh\nopenssl genrsa -out server-key.pem 4096\n```\n\n## 绑定 IP 或者域名\n\n$HOST 这个值，填写你的服务器外网 IP 或者服务器外网域名\n\n```sh\nopenssl req -subj \"/CN=$HOST\" -sha256 -new -key server-key.pem -out server.csr\n```\n\n## 配置白名单\n\n$HOST 就是你第六步设置的那个 $HOST, **注意如果你用的 IP, 则需要把 DNS 改为 IP**\n\n你如果希望只有指定的 IP 能够访问的话，请把 0.0.0.0 改为指定 IP，不过一般情况下，个人的网络是没有固定的公网 IP 的，所以建议设置成 0.0.0.0，但是需要证书才能访问\n\n```sh\necho subjectAltName = DNS:$HOST,IP:0.0.0.0 >> extfile.cnf\necho subjectAltName = IP:$HOST,IP:0.0.0.0 >> extfile.cnf\n# 下面是我的\necho subjectAltName = IP:1.1.1.10,IP:0.0.0.0 >> extfile.cnf\n```\n\n## 生成 ca-key\n\n```sh\necho extendedKeyUsage = serverAuth >> extfile.cnf\n\n# 执行这一句需要输入之前设置的密码\nopenssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\-CAcreateserial -out server-cert.pem -extfile extfile.cnf\n\nopenssl genrsa -out key.pem 4096\n\nopenssl req -subj '/CN=client' -new -key key.pem -out client.csr\n\necho extendedKeyUsage = clientAuth >> extfile.cnf\n```\n\n## 生成 cert.pem\n\n```sh\n# 需要输入之前设置的密码\nopenssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\-CAcreateserial -out cert.pem -extfile extfile.cnf\n```\n\n## 修改权限\n\n```sh\nchmod -v 0400 ca-key.pem key.pem server-key.pem\nchmod -v 0444 ca.pem server-cert.pem cert.pem\n```\n\n## 把证书复制过去\n\n```sh\ncp server-*.pem  /etc/docker/\ncp ca.pem /etc/docker/\n```\n\n## 修改 docker 的配置\n\n```sh\nvim /lib/systemd/system/docker.service\n```\n\n在`/usr/bin/dockerd`后面添加`--tlsverify --tlscacert=/etc/docker/ca.pem --tlscert=/etc/docker/server-cert.pem --tlskey=/etc/docker/server-key.pem -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock `\n\n```ini\nExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n# 替换为下面\n\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.pem --tlscert=/etc/docker/server-cert.pem --tlskey=/etc/docker/server-key.pem -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock -H fd:// --containerd=/run/containerd/containerd.sock\n```\n\n## 重启 docker\n\n```sh\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n## 下载连接所需的证书文件\n\n把这几个文件下载到你的电脑上，新建一个文件夹供着\n\n![](https://cdn.wenzuo.net/assets/202201101203285.png)\n\n![](https://cdn.wenzuo.net/assets/202201101203956.png)\n\n## 通过 IDEA 的 docker 插件进行连接\n\n默认是 tcp 的，你要改成 https，端口你之前设置的什么端口就是什么端口, 然后选择你放证书的那个文件夹\n\n![](https://cdn.wenzuo.net/assets/202201101203300.png)\n\n## 连接到远程 docker\n\n成功连接，连接不上的，查找如下原因\n\n1、tcp 连接没换\n2、端口不对\n3、服务器防火墙没放端口\n4、云服务器防火墙没放端口\n5、证书没弄好\n","tags":["Docker"],"categories":["编程笔记"]},{"title":"虚拟机安装Debian","url":"/posts/127f2230.html","content":"\n## 下载镜像\n\nhttp://mirrors.163.com/debian-cd/10.7.0/amd64/iso-cd/debian-10.7.0-amd64-netinst.iso\n\n下载完成后, 打开 PD, 选择镜像安装即可, 在选择安装软件时我选择的: ssh server 和 标准工具集\n\n<!-- more -->\n\n## 易用性配置\n\n### root 用户登录\n\n安装完成后, 修改配置以允许 root 用户 ssh 登录\n\n```sh\ncd /etc/ssh/\nvim sshd_config\n\n# 如下项修改\nLoginGraceTime 120m\nPermitRootLogin yes\nStrictModes yes\n```\n\n### 修改 hostname\n\n```sh\nhostnamectl set-hostname custom-hostname\n```\n\n### 替换阿里源\n\n备份\n\n```sh\ncp /etc/apt/sources.list /etc/apt/sources.list.bak\n```\n\n创建新的 sources.list, 粘贴如下内容\n\n`vim sources.list`\n\n```\ndeb http://mirrors.aliyun.com/debian/ buster main non-free contrib\ndeb http://mirrors.aliyun.com/debian-security buster/updates main\ndeb http://mirrors.aliyun.com/debian/ buster-updates main non-free contrib\ndeb http://mirrors.aliyun.com/debian/ buster-backports main non-free contrib\n\ndeb-src http://mirrors.aliyun.com/debian/ buster main non-free contrib\ndeb-src http://mirrors.aliyun.com/debian-security buster/updates main\ndeb-src http://mirrors.aliyun.com/debian/ buster-updates main non-free contrib\ndeb-src http://mirrors.aliyun.com/debian/ buster-backports main non-free contrib\n```\n\n其他源参考: https://cloud.tencent.com/developer/article/1590080\n\n### 常用软件安装\n\n```sh\napt install curl vim\n```\n","tags":["Linux"],"categories":["编程笔记"]},{"title":"使用iTerm2 Profiles快捷登录ssh","url":"/posts/6e724d2a.html","content":"\n首先在本地文件夹创建一个登录脚本, 如: /Users/zhanghao/Documents/iterm2-ssh/my-ecs.sh\n\n<!-- more -->\n\n脚本内容如下:\n\n```sh\n#!/usr/bin/expect\n\nset PORT <你的服务器ssh端口号>\nset HOST <你的服务器ip>\nset USER <你的用户名>\nset PASSWORD <你的密码>\n\nspawn ssh -p $PORT $USER@$HOST\nexpect {\n        \"yes/no\" {send \"yes\\r\";exp_continue;}\n         \"*password:*\" { send \"$PASSWORD\\r\" }\n        }\ninteract\n```\n\n保存之后, 打开 iterm2 的首选项, 在 profiles 中新建一个 profile, 填写 name 便于自己识别, command 中设置登录脚本为刚才编写的脚本文件的路径\n\n![](https://cdn.wenzuo.net/assets/202201101202810.png)\n\n设置完成之后, 可在顶部菜单栏看到, 点击即可快捷登录 ssh\n\n![](https://cdn.wenzuo.net/assets/202201101203848.png)\n","tags":["iTerm"],"categories":["编程笔记"]},{"title":"Docker 实战","url":"/posts/8b6bb294.html","content":"\n## 安装 Docker\n\n```sh\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\n```\n\n<!-- more -->\n\n### centos8 错误\n\n在 centos8 上会提示如下错误\n\n```\n错误：\n 问题: package docker-ce-3:20.10.2-3.el7.x86_64 requires containerd.io >= 1.4.1, but none of the providers can be installed\n  - cannot install the best candidate for the job\n  - package containerd.io-1.4.3-3.1.el7.x86_64 is filtered out by modular filtering\n```\n\n### 解决\n\n```sh\ncd /etc/yum.repos.d\nvim docker-ce.repo\n```\n\n将 `baseurl`中的 7 都改为 8, 然后重建缓存\n\n```sh\ndnf makecache\n```\n\n安装 docker-ce\n\n```sh\nyum install docker-ce\n```\n\n## 设置国内镜像\n\n使用加速器可以提升获取 Docker 官方镜像的速度\n\n在此之前你需要先启动一次 docker\n\n```sh\nsystemctl start docker\n```\n\n创建并编辑 `/etc/docker/daemon.json`\n\n```sh\nvim /etc/docker/daemon.json\n```\n\n阿里云镜像获取地址：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors，登陆后，左侧菜单选中镜像加速器就可以看到你的专属地址了, 替换下面的地址\n\n```json\n{\n  \"registry-mirrors\": [\"https://<阿里云ID>.mirror.aliyuncs.com\"]\n}\n```\n\n{\n\"registry-mirrors\": [\"https://7c4lu2pa.mirror.aliyuncs.com\"]\n}\n\n重启\n\n```sh\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n```\n","tags":["Docker"],"categories":["编程笔记"]},{"title":"mac 下使用 lrzsz","url":"/posts/35b88dbe.html","content":"\n## 介绍\n\n在 mac 下，实现与服务器进行便捷的文件上传和下载操作。\n\n<!-- more -->\n\n## 步骤\n\n1. 安装支持 rz 和 sz 命令的 lrzsz：`brew install lrzsz`\n\n2. 在本地`/usr/local/bin/`目录下保存`iterm2-send-zmodem.sh`和`iterm2-recv-zmodem.sh`两个脚本, 下面有备用\n\n3. 设置一下两个脚本的权限，一般 chmod 777 就行了 `chmod 777 /usr/local/bin/iterm2-*`\n\n4. 设置 Iterm2 的 Tirgger 特性，profiles->default->editProfiles->Advanced 中的 Tirgger\n\n5. 添加两条 trigger，分别设置 Regular expression，Action，Parameters，Instant 如下：\n\n   ```\n   1.第一条\n           Regular expression: rz waiting to receive.\\*\\*B0100\n           Action: Run Silent Coprocess\n           Parameters: /usr/local/bin/iterm2-send-zmodem.sh\n           Instant: checked\n   2.第二条\n           Regular expression: \\*\\*B00000000000000\n           Action: Run Silent Coprocess\n           Parameters: /usr/local/bin/iterm2-recv-zmodem.sh\n           Instant: checked\n   ```\n\n   ![](https://cdn.wenzuo.net/assets/202201101202171.png)\n\n### iterm2-recv-zmodem.sh\n\n```sh\n#!/bin/bash\n# 这个脚本来自 github，https://github.com/aikuyun/iterm2-zmodem/blob/master/iterm2-recv-zmodem.sh\n\nosascript -e 'tell application \"iTerm2\" to version' > /dev/null 2>&1 && NAME=iTerm2 || NAME=iTerm\nif [[ $NAME = \"iTerm\" ]]; then\n\tFILE=$(osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"&(quoted form of POSIX path of thefile as Unicode text)&\\\"\\\")\")\nelse\n\tFILE=$(osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose folder with prompt \"Choose a folder to place received files in\"' -e \"do shell script (\\\"echo \\\"&(quoted form of POSIX path of thefile as Unicode text)&\\\"\\\")\")\nfi\n\nif [[ $FILE = \"\" ]]; then\n\techo Cancelled.\n\t# Send ZModem cancel\n\techo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18\n\tsleep 1\n\techo\n\techo \\# Cancelled transfer\nelse\n\tcd \"$FILE\"\n\t/usr/local/bin/rz -E -e -b --bufsize 4096\n\tsleep 1\n\techo\n\techo\n\techo \\# Sent \\-\\> $FILE\nfi\n```\n\n### iterm2-send-zmodem.sh\n\n```sh\n#!/bin/bash\n# 这个脚本来自 github，https://github.com/aikuyun/iterm2-zmodem/blob/master/iterm2-send-zmodem.sh\n\nosascript -e 'tell application \"iTerm2\" to version' > /dev/null 2>&1 && NAME=iTerm2 || NAME=iTerm\nif [[ $NAME = \"iTerm\" ]]; then\n\tFILE=`osascript -e 'tell application \"iTerm\" to activate' -e 'tell application \"iTerm\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"&(quoted form of POSIX path of thefile as Unicode text)&\\\"\\\")\"`\nelse\n\tFILE=`osascript -e 'tell application \"iTerm2\" to activate' -e 'tell application \"iTerm2\" to set thefile to choose file with prompt \"Choose a file to send\"' -e \"do shell script (\\\"echo \\\"&(quoted form of POSIX path of thefile as Unicode text)&\\\"\\\")\"`\nfi\nif [[ $FILE = \"\" ]]; then\n\techo Cancelled.\n\t# Send ZModem cancel\n\techo -e \\\\x18\\\\x18\\\\x18\\\\x18\\\\x18\n\tsleep 1\n\techo\n\techo \\# Cancelled transfer\nelse\n\t/usr/local/bin/sz \"$FILE\" --escape --binary --bufsize 4096\n\tsleep 1\n\techo\n\techo \\# Received $FILE\nfi\n```\n","tags":["Mac"],"categories":["编程笔记"]},{"title":"SpringBoot 参数校验","url":"/posts/ea7ab733.html","content":"\n<!-- more -->\n\n## 准备工作\n\n引入相关依赖\n\n```xml\n<dependency>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter-validation</artifactId>\n</dependency>\n```\n\n## Bean Validation 中的约束\n\n| 约束                        | 说明                                                     |\n| --------------------------- | -------------------------------------------------------- |\n| @Null                       | 被注释的元素必须为 null                                  |\n| @NotNull                    | 被注释的元素必须不为 null                                |\n| @AssertTrue                 | 被注释的元素必须为 true                                  |\n| @AssertFalse                | 被注释的元素必须为 false                                 |\n| @Min(value)                 | 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 |\n| @Max(value)                 | 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 |\n| @DecimalMin(value)          | 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 |\n| @DecimalMax(value)          | 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 |\n| @Size(max, min)             | 被注释的元素的大小必须在指定的范围内                     |\n| @Digits (integer, fraction) | 被注释的元素必须是一个数字，其值必须在可接受的范围内     |\n| @Past                       | 被注释的元素必须是一个过去的日期                         |\n| @Future                     | 被注释的元素必须是一个将来的日期                         |\n| @Pattern(value)             | 被注释的元素必须符合指定的正则表达式                     |\n\n## Hibernate Validator 附加的约束\n\n| 约束      | 说明                                   |\n| --------- | -------------------------------------- |\n| @Email    | 被注释的元素必须是电子邮箱地址         |\n| @Length   | 被注释的字符串的大小必须在指定的范围内 |\n| @NotEmpty | 被注释的字符串的必须非空               |\n| @Range    | 被注释的元素必须在合适的范围内         |\n\n## 代码中校验\n\nspring 中可以直接从 aop 容器中获取\n\n```java\n@Autowired\nprivate Validator validator;\n```\n\n通过工厂方法获取\n\n```java\nValidatorFactory factory = Validation.buildDefaultValidatorFactory();\nValidator validator = factory.getValidator();\nSet<ConstraintViolation<DemoDTO>> violations = validator.validate(dto);\n```\n\n## @Validated 与@Valid 的简单对比说明\n\n@Valid 注解与@Validated 注解功能大部分类似；两者的不同主要在于:\n\n- @Valid 属于 javax 下的，而@Validated 属于 Spring 下\n- @Valid 支持嵌套校验，而@Validated 不支持\n- @Validated 支持分组，而@Valid 不支持\n\n## 普通方法校验参数\n\n除了验证接口，我们还可以验证普通的方法，首先在需要验证的方法所在类上面增加注解 @Validated\n\n```java\n@Validated\n@Service\npublic class DemoService {\n  public void demo(@Valid DemoDTO dto) {\n  }\n}\n```\n\n**注意：**\n\n- 基于 aop 机制，被验证的方法需要注册为组件\n- 只能在类上面增加注解@Validated，不能在单个方法上\n- 抛出的异常为 ConstraintViolationException，需要单独拦截，示例：\n\n```java\n@ResponseBody\n@ExceptionHandler(ConstraintViolationException.class)\npublic HttpResponse handle(ConstraintViolationException e) {\n    return HttpResponse.builder().code(500).msg(\n        e.getConstraintViolations()\n        .stream()\n        .findFirst()\n        .map(ConstraintViolation::getMessage)\n        .orElse(\"参数校验失败\")).build();\n}\n```\n\n## 嵌套验证\n\n当我们要验证的类 DemoBO 有成员属性为 OtherObject，对 OtherObject 中的属性进行校验，需要在 DemoBO 的成员属性 OtherObject 之上加上 @Valid\n\n```java\n@Data\npublic class DemoBO {\n\n    @Valid\n    private OtherObject otherObject;\n}\n```\n\n## 分组校验\n\n在很多时候，同一个模型可能会在多处被用到，但每处的校验场景又不一定相同(如：新增用户接口、修改用户接口,参数都是 User 模型，在新增时 User 中 name 字段不能为空，userNo 字段可以为空；在修改时 User 中 name 字段可以为空，userNo 字段不能为空)。我们可以用 groups 来实现:**同一个模型在不同场景下，(动态区分)校验模型中的不同字段。**\n\n创建分组 Create 和 Update 继承 Default\n\n继承 Default 并不是必须的。只是说，如果继承了 Default，那么@Validated(value = Create.class)的校验范畴就为【Create】和【Default】；如果没继承 Default，那么@Validated(value = Create.class)的校验范畴只为【Create】，而@Validated(value = {Create.class, Default.class})的校验范畴才为【Create】【Default】。\n\nDefault 组和无参构造机制类似，当没有指定分组时，会默认当前校验属于 Default 组，但是一旦主动给当前校验指定\n了分组(如上图中的 name 字段，主动指定了属于 Create 组)，那么就不会再额外指定属于 Default 组了。\n当然，也可以画蛇添足的主动指定所属分组为 Default。\n\n```java\nimport javax.validation.groups.Default;\n\npublic interface Create extends Default{}\n```\n\n```java\nimport javax.validation.groups.Default;\n\npublic interface Update extends Default{}\n```\n\n创建实体类 Student\n\n```java\n\n@Data\npublic class Student{\n\n  @NotNull(groups=Update.class)\n  private Long id;\n\n  @NotEmpty(groups=Create.class)\n  private String name;\n\n  @NotEmpty\n  private Integer age;\n\n  @NotEmpty(groups=Default.class) // 等价于 @NotEmpty\n  private Integer gender;\n}\n```\n","tags":["SpringBoot"],"categories":["编程笔记"]},{"title":"maven多仓库配置 - 公司仓库与阿里云仓库共存","url":"/posts/5fe040af.html","content":"\n<!-- more -->\n\n以下操作在 maven 配置文件 `settings.xml` 中修改\n\n## 配置公司账户信息 `server`\n\n```xml\n<servers>\n  <server>\n    <id>nexus</id>\n    <username>xxx</username>\n    <password>xxx</password>\n  </server>\n</servers>\n```\n\n## 删除掉原来的 `mirror`\n\n```xml\n<mirrors>\n</mirrors>\n```\n\n## 配置公司和阿里云 `profile`\n\n```xml\n<profiles>\n  <profile>\n    <id>nexus</id>\n    <repositories>\n      <repository>\n        <id>nexus-pub</id>\n        <name>private-nexus</name>\n        <url>http://192.168.50.1:8899/nexus/content/groups/public/</url>\n        <releases>\n          <enabled>true</enabled>\n        </releases>\n        <snapshots>\n          <enabled>true</enabled>\n          <updatePolicy>always</updatePolicy>\n        </snapshots>\n      </repository>\n    </repositories>\n    <pluginRepositories>\n      <pluginRepository>\n        <id>nexus-pub</id>\n        <name>private nexus</name>\n        <url>http://192.168.50.1:8899/nexus/content/groups/public/</url>\n        <releases>\n          <enabled>true</enabled>\n        </releases>\n        <snapshots>\n          <enabled>true</enabled>\n          <updatePolicy>always</updatePolicy>\n        </snapshots>\n      </pluginRepository>\n    </pluginRepositories>\n  </profile>\n  <profile>\n    <id>aliyun</id>\n    <repositories>\n      <repository>\n        <id>central</id>\n        <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n      </repository>\n    </repositories>\n    <pluginRepositories>\n      <pluginRepository>\n        <id>central</id>\n        <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n      </pluginRepository>\n    </pluginRepositories>\n  </profile>\n</profiles>\n```\n\n## 配置 `activeProfiles`\n\n```xml\n<activeProfiles>\n  <activeProfile>nexus</activeProfile>\n  <activeProfile>aliyun</activeProfile>\n</activeProfiles>\n```\n","tags":["Maven"],"categories":["编程笔记"]},{"title":"http 状态码大全","url":"/posts/7d5aa36c.html","content":"\n## 1xx 消息\n\n▪ 100 Continue\n▪ 101 Switching Protocols\n▪ 102 Processing\n\n<!-- more -->\n\n## 2xx 成功\n\n▪ 200 OK\n▪ 201 Created\n▪ 202 Accepted\n▪ 203 Non-Authoritative Information\n▪ 204 No Content\n▪ 205 Reset Content\n▪ 206 Partial Content\n▪ 207 Multi-Status\n\n## 3xx 重定向\n\n▪ 300 Multiple Choices\n▪ 301 Moved Permanently\n▪ 302 Move Temporarily\n▪ 303 See Other\n▪ 304 Not Modified\n▪ 305 Use Proxy\n▪ 306 Switch Proxy\n▪ 307 Temporary Redirect\n\n## 4xx 请求错误\n\n▪ 400 Bad Request\n▪ 401 Unauthorized\n▪ 402 Payment Required\n▪ 403 Forbidden\n▪ 404 Not Found\n▪ 405 Method Not Allowed\n▪ 406 Not Acceptable\n▪ 407 Proxy Authentication Required\n▪ 408 Request Timeout\n▪ 409 Conflict\n▪ 410 Gone\n▪ 411 Length Required\n▪ 412 Precondition Failed\n▪ 413 Request Entity Too Large\n▪ 414 Request-URI Too Long\n▪ 415 Unsupported Media Type\n▪ 416 Requested Range Not Satisfiable\n▪ 417 Expectation Failed\n▪ 418 I'm a teapot\n▪ 421 Misdirected Request\n▪ 422 Unprocessable Entity\n▪ 423 Locked\n▪ 424 Failed Dependency\n▪ 425 Too Early\n▪ 426 Upgrade Required\n▪ 449 Retry With\n▪ 451 Unavailable For Legal Reasons\n\n## 5xx 服务器错误\n\n▪ 500 Internal Server Error\n▪ 501 Not Implemented\n▪ 502 Bad Gateway\n▪ 503 Service Unavailable\n▪ 504 Gateway Timeout\n▪ 505 HTTP Version Not Supported\n▪ 506 Variant Also Negotiates\n▪ 507 Insufficient Storage\n▪ 509 Bandwidth Limit Exceeded\n▪ 510 Not Extended\n▪ 600 Unparseable Response Headers\n","tags":["Http"],"categories":["编程笔记"]},{"title":"springboot-starter-kit 企业级脚手架","url":"/posts/456efc00.html","content":"\n本文将从零开始搭建一个 springboot-starter-kit 脚手架项目，以支持当前主流的前后端分离架构，开箱即用，快速开发！\n\n<!-- more -->\n\n## 模块分层\n\napi(controller) --> service --> mapper(dao) --> pojo(entity) --> common\n\n## logback 日志处理\n\n在 api 模块的 resources 目录下创建 logback-spring.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n\n    <!-- 日志文件存放路径 -->\n    <!--    <property name=\"logback.dir\" value=\"/Users/zhanghao/data/@project.name@/log\"/>-->\n    <springProperty scope=\"context\" name=\"logback.dir\" source=\"logging.logback.dir\"/>\n\n    <!-- 彩色日志依赖的渲染类 -->\n    <conversionRule conversionWord=\"clr\"\n                    converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/>\n    <conversionRule conversionWord=\"wex\"\n                    converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/>\n    <conversionRule conversionWord=\"wEx\"\n                    converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/>\n\n    <!-- 控制台日志渲染格式 -->\n    <property name=\"CONSOLE_LOG_PATTERN\"\n              value=\"${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-HH:mm:ss.SSS}}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(-){faint} %clr([%13.13t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\"/>\n    <!-- 日志文件渲染格式 -->\n    <property name=\"FILE_LOG_PATTERN\"\n              value=\"${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } - [%13.13t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\"/>\n\n\n    <!-- 输出到控制台 -->\n    <appender name=\"consoleLog\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <!-- 日志格式 -->\n        <layout class=\"ch.qos.logback.classic.PatternLayout\">\n            <pattern>\n                ${CONSOLE_LOG_PATTERN}\n            </pattern>\n        </layout>\n        <!-- 日志等级 -->\n        <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n            <level>INFO</level>\n        </filter>\n    </appender>\n\n    <appender name=\"fileInfoLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <!-- 如果只是想要 Info 级别的日志，只是过滤 info 还是会输出 Error 日志，因为 Error 的级别高，\n        所以我们使用下面的策略，可以避免输出 Error 的日志 -->\n        <filter class=\"ch.qos.logback.classic.filter.LevelFilter\">\n            <!-- 过滤 Error -->\n            <level>ERROR</level>\n            <!-- 匹配到就禁止 -->\n            <onMatch>DENY</onMatch>\n            <!-- 没有匹配到就允许 -->\n            <onMismatch>ACCEPT</onMismatch>\n        </filter>\n        <!-- 日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则\n            如果同时有<File>和<FileNamePattern>，那么当天日志是<File>，明天会自动把今天\n            的日志改名为今天的日期。即，<File> 的日志都是当天的。-->\n        <File>${logback.dir}/info.log</File>\n        <!--滚动策略，按照时间滚动 TimeBasedRollingPolicy-->\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间-->\n            <FileNamePattern>${logback.dir}/info.%d{yyyy-MM-dd}.log</FileNamePattern>\n            <!--只保留最近90天的日志-->\n            <maxHistory>90</maxHistory>\n            <!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志-->\n            <!--<totalSizeCap>1GB</totalSizeCap>-->\n        </rollingPolicy>\n        <!--日志输出编码格式化-->\n        <encoder>\n            <charset>UTF-8</charset>\n            <pattern>${FILE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n\n\n    <appender name=\"fileErrorLog\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <!--如果只是想要 Error 级别的日志，那么需要过滤一下，默认是 info 级别的，ThresholdFilter-->\n        <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n            <level>Error</level>\n        </filter>\n        <!--日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则\n            如果同时有<File>和<FileNamePattern>，那么当天日志是<File>，明天会自动把今天\n            的日志改名为今天的日期。即，<File> 的日志都是当天的。\n        -->\n        <File>${logback.dir}/error.log</File>\n        <!--滚动策略，按照时间滚动 TimeBasedRollingPolicy-->\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间-->\n            <FileNamePattern>${logback.dir}/error.%d{yyyy-MM-dd}.log</FileNamePattern>\n            <!--只保留最近90天的日志-->\n            <maxHistory>90</maxHistory>\n            <!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志-->\n            <!--<totalSizeCap>1GB</totalSizeCap>-->\n        </rollingPolicy>\n        <!--日志输出编码格式化-->\n        <encoder>\n            <charset>UTF-8</charset>\n            <pattern>${FILE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n\n    <!--指定最基础的日志输出级别-->\n    <root level=\"INFO\">\n        <!-- appender 将会添加到这个 logger -->\n        <appender-ref ref=\"consoleLog\"/>\n        <appender-ref ref=\"fileInfoLog\"/>\n        <appender-ref ref=\"fileErrorLog\"/>\n    </root>\n\n</configuration>\n```\n\n在 application.yml 中添加日志根目录\n\n```yml\nlogging:\n  logback:\n    dir: /Users/zhanghao/data/springboot-starter-kit/log\n```\n\n## 统一响应对象\n\n异常对象枚举\n\n```java\npackage org.example.common.enums;\n\n/**\n * 错误码与错误信息枚举类\n *\n * @author zhanghao13\n * @since 2020/11/17 20:39\n */\npublic enum RetEnum {\n\n    OK(200, \"成功\"),\n    BAD_REQUEST(400, \"参数错误\"),\n    UNAUTHORIZED(401, \"您未登录或您的登录信息已过期，请重新登录\"),\n    FORBIDDEN(403, \"您没有该权限\"),\n    NOT_FOUND(404, \"您请求的资源未找到\"),\n    SERVER_ERROR(500, \"服务器异常\"),\n    ;\n\n    public final int code;\n    public final String msg;\n\n    RetEnum(int code, String msg) {\n        this.code = code;\n        this.msg = msg;\n    }\n}\n```\n\n统一响应对象\n\n```java\npackage org.example.common;\n\nimport lombok.Data;\nimport lombok.experimental.Accessors;\nimport org.example.common.enums.RetEnum;\n\nimport java.io.Serializable;\n\n/**\n * 统一响应, 用于返回 json 响应体\n *\n * @author zhanghao13\n * @since 2020/11/17 20:31\n */\n@Data\n@Accessors(chain = true)\npublic class Ret implements Serializable {\n\n    private static final long serialVersionUID = 2665482313176083754L;\n\n    private int code;\n    private String msg;\n    private Object data;\n\n    public static Ret ok() {\n        return new Ret().setCode(RetEnum.OK.code).setMsg(RetEnum.OK.msg);\n    }\n\n    public static Ret ok(Object data) {\n        return Ret.ok().setData(data);\n    }\n\n    public static Ret fail(int code, String msg) {\n        return new Ret().setCode(code).setMsg(msg);\n    }\n\n    public static Ret fail(String msg) {\n        return Ret.fail(RetEnum.BAD_REQUEST.code, msg);\n    }\n\n    public static Ret fail(RetEnum retEnum) {\n        return Ret.fail(retEnum.code, retEnum.msg);\n    }\n\n    // ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓以下为常用业务失败封装↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n\n    public static Ret badRequest() {\n        return Ret.fail(RetEnum.BAD_REQUEST);\n    }\n\n    public static Ret unauthorized() {\n        return Ret.fail(RetEnum.UNAUTHORIZED);\n    }\n\n    public static Ret forbidden() {\n        return Ret.fail(RetEnum.FORBIDDEN);\n    }\n\n    public static Ret notFound() {\n        return Ret.fail(RetEnum.NOT_FOUND);\n    }\n\n    public static Ret serverError() {\n        return Ret.fail(RetEnum.SERVER_ERROR);\n    }\n\n}\n```\n\n## 业务异常类\n\n```java\npackage org.example.common.exception;\n\n/**\n * 参数校验异常类\n * 此异常阻止了异常栈追踪信息, 提高了性能, 避免抛出不必要的异常栈, 干扰调试\n *\n * @author zhanghao13\n * @since 2020/11/18 14:29\n */\npublic class ServiceException extends RuntimeException {\n\n    private static final long serialVersionUID = -3287961933635362725L;\n\n    /**\n     * 仅记录异常信息, 不记录 cause by 和 stack trace, 提高性能\n     *\n     * @param message 异常信息\n     */\n    public ServiceException(String message) {\n        /*\n          message  异常的描述信息，也就是在打印栈追踪信息时异常类名后面紧跟着的描述字符串\n          cause    导致此异常发生的父异常，即追踪信息里的caused by\n          enableSuppress   关于异常挂起的参数，这里我们永远设为false即可\n          writableStackTrace   表示是否生成栈追踪信息，只要将此参数设为false, 则在构造异常对象时就不会调用fillInStackTrace()\n         */\n        super(message, null, false, false);\n    }\n\n}\n```\n\n## 全局异常处理\n\n```java\npackage org.example.api.configuration;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.example.common.Ret;\nimport org.example.common.exception.ServiceException;\nimport org.springframework.web.bind.annotation.ControllerAdvice;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n/**\n * 全局统一异常处理类\n *\n * @author zhanghao13\n * @since 2020/11/18 19:44\n */\n@Slf4j\n@ControllerAdvice\npublic class ExceptionConfiguration {\n\n    /**\n     * 业务异常处理器: 如参数错误\n     *\n     * @param e 异常对象\n     * @return Ret\n     */\n    @ExceptionHandler(ServiceException.class)\n    @ResponseBody\n    public Ret handler(ServiceException e) {\n        log.info(e.getMessage(), e);\n        return Ret.fail(e.getMessage());\n    }\n\n    /**\n     * 默认异常处理器\n     *\n     * @param e 异常对象\n     * @return Ret\n     */\n    @ExceptionHandler(Exception.class)\n    @ResponseBody\n    public Ret handler(Exception e) {\n        log.error(e.getMessage(), e);\n        return Ret.serverError();\n    }\n\n}\n```\n\n## 全局请求响应参数及耗时记录\n\n## 异步调用处理\n\n## Redis 整合及序列化处理\n\n## Knife4j 接口文档整合\n","tags":["SpringBoot"],"categories":["编程笔记"]},{"title":"修复由于 zsh-autosuggestions 造成的粘贴慢","url":"/posts/5b86813b.html","content":"\n使用 `zsh` 在开启 zsh-autosuggestions 插件的时候，粘贴命令会像打字一样，尤其是长段的命令，需要等很长时间\n\n官方有一个 issues 专门来讨论这个问题：https://github.com/zsh-users/zsh-autosuggestions/issues/238\n\n解决办法：将以下代码粘贴到 `.zshrc` 文件中即可\n\n<!-- more -->\n\n```bash\n# This speeds up pasting w/ autosuggest\n# https://github.com/zsh-users/zsh-autosuggestions/issues/238\npasteinit() {\n  OLD_SELF_INSERT=${${(s.:.)widgets[self-insert]}[2,3]}\n  zle -N self-insert url-quote-magic # I wonder if you'd need `.url-quote-magic`?\n}\n\npastefinish() {\n  zle -N self-insert $OLD_SELF_INSERT\n}\nzstyle :bracketed-paste-magic paste-init pasteinit\n```\n","tags":["Linux"],"categories":["编程笔记"]},{"title":"Java8 Stream API","url":"/posts/968e741a.html","content":"\n## 概述\n\nStream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。\n\n<!-- more -->\n\nStream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。\n\n而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。\n\nStream 的另外一大特点是，数据源本身可以是无限的。\n\n获取一个数据源（source）→ 数据转换 → 执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。\n\n![](https://cdn.wenzuo.net/assets/202201101202422.png)\n\n## 流的操作类型\n\n流的操作类型分为两种：\n\n- Intermediate ：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。\n- Terminal ：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。\n\n## 生成 Stream Source 的几种方式\n\n### Stream\n\n```java\njava.util.stream.Stream.empty(T... values)\njava.util.stream.Stream.of(T t)\njava.util.stream.Stream.of(T... values)\njava.util.stream.Stream.iterate(final T seed, final UnaryOperator<T> f)\njava.util.stream.Stream.builder().build()\njava.util.stream.Stream.concat(Stream<? extends T> a, Stream<? extends T> b)\njava.util.stream.Stream.generate(Supplier<T> s)\n\n// 以上大多数方法同样适用于\njava.util.stream.IntStream\njava.util.stream.LongStream\njava.util.stream.DoubleStream\n```\n\n### Collection\n\n```java\njava.util.Collection.stream()\njava.util.Collection.parallelStream()\n```\n\n### Arrays\n\n```java\njava.util.Arrays.stream(T[] array)\n```\n\n### Reader\n\n```java\njava.io.BufferedReader.lines()\n```\n\n### Files\n\n```java\njava.nio.file.Files.list(Path dir)\njava.nio.file.Files.walk(Path start, int maxDepth, FileVisitOption... options)\njava.nio.file.Files.walk(Path start, FileVisitOption... options)\njava.nio.file.Files.find(Path start, int maxDepth, BiPredicate<Path, BasicFileAttributes> matcher, FileVisitOption... options)\njava.nio.file.Files.lines(Path path, Charset cs)\njava.nio.file.Files.lines(Path path)\n```\n\n### Random\n\n```java\njava.util.Random.ints()\njava.util.Random.ints(long streamSize)\njava.util.Random.ints(int randomNumberOrigin, int randomNumberBound)\njava.util.Random.ints(long streamSize, int randomNumberOrigin, int randomNumberBound)\n\njava.util.Random.longs()\njava.util.Random.longs(long streamSize)\njava.util.Random.longs(long randomNumberOrigin, long randomNumberBound)\njava.util.Random.longs(long streamSize, long randomNumberOrigin, long randomNumberBound)\n\njava.util.Random.doubles()\njava.util.Random.doubles(long streamSize)\njava.util.Random.doubles(double randomNumberOrigin, double randomNumberBound)\njava.util.Random.doubles(long streamSize, double randomNumberOrigin, double randomNumberBound)\n```\n\n### 其他\n\n```java\njava.util.BitSet.stream()\njava.util.regex.Pattern.splitAsStream(final CharSequence input)\njava.util.jar.JarFile.stream()\n```\n\n## Stream 常用操作举例\n\n### 准备工作\n\n首先创建 `User` 实体类\n\n```java\n@Data\n@AllArgsConstructor\npublic class User {\n\n    private Long id;\n    private String name;\n    private Integer age;\n    private BigDecimal money;\n}\n```\n\n然后添加一些测试数据\n\n```java\nList<User> userList=new ArrayList<>();\n\nUser user1=new User(1L,\"user1\",15, BigDecimal.valueOf(100.55));\nUser user2=new User(2L,\"user2\",16, BigDecimal.valueOf(200.14));\nUser user3=new User(3L,\"user3\",17, BigDecimal.valueOf(300.00));\nUser user4=new User(4L,\"user4\",18, BigDecimal.valueOf(400.89));\nUser user5=new User(5L,\"user5\",19, BigDecimal.valueOf(500.66));\n\nuserList.add(user1);\nuserList.add(user2);\nuserList.add(user3);\nuserList.add(user4);\nuserList.add(user5);\n\nStream<User> userStream = userList.stream();\n```\n\n### 排序\n\n```java\npublic static void example(List<User> userList) {\n    List<User> users;\n\n    // 正序\n    users = userList.stream().sorted(Comparator.comparing(User::getAge))\n            .collect(Collectors.toList());\n    users.forEach(System.out::println);\n\n    // 倒序\n    users = userList.stream().sorted(Comparator.comparing(User::getAge).reversed())\n            .collect(Collectors.toList());\n    users.forEach(System.out::println);\n\n    // 多重排序\n    users = userList.stream().sorted(\n            Comparator.comparing(User::getAge)\n                    .thenComparing(User::getId).reversed()\n    )\n            .collect(Collectors.toList());\n    users.forEach(System.out::println);\n}\n```\n\n### 转换\n\n```java\npublic static void example(List<User> userList) {\n    List<String> names;\n\n    // 可以自由对 user 做转换\n    names = userList.stream().map(user -> user.getName()).collect(Collectors.toList());\n    names.forEach(System.out::println);\n\n    // 上面写法可以简写如下\n    names = userList.stream().map(User::getName).collect(Collectors.toList());\n    names.forEach(System.out::println);\n}\n```\n\n### 处理\n\n**注意 peek 与 map 的区别是:**\n**peek 操作 一般用于不想改变流中元素本身的类型或者只想操作元素的内部状态时；**\n**而 map 则用于改变流中元素本身类型，即从元素中派生出另一种类型的操作。**\n\n```java\npublic static void example(List<User> userList) {\n    List<String> names;\n\n    // 可以自由对 user 属性做修改\n    names = userList.stream().peek(user -> user.setName(\"小名\")).collect(Collectors.toList());\n    names.forEach(System.out::println);\n}\n```\n\n### 分组\n\n可以针对对象的某一属性进行分组，比如根据年龄分组\n\n```java\npublic static void example(List<User> userList) {\n    // lambda 表达式的返回值作为 key, List<User> 作为 value\n\n    //根据年龄转换为 map\n    Map<Integer, List<User>> map1 = userList.stream().collect(Collectors.groupingBy(User::getAge));\n\n    // 根据年龄段转换为 map\n    Map<String, List<User>> map2 = userList.stream().collect(Collectors.groupingBy(user -> {\n        if (user.getAge() <= 17) {\n            return \"少年\";\n        } else if (user.getAge() <= 40) {\n            return \"青年\";\n        } else if (user.getAge() <= 65) {\n            return \"中年\";\n        } else {\n            return \"老年\";\n        }\n    }));\n}\n```\n\n### 转 Map\n\n```java\npublic static void example(List<User> userList) {\n    Map<Integer, User> map;\n\n    map = userList.stream().collect(Collectors.toMap(user -> user.getAge(), user -> user));\n    // 上面写法可以简写如下\n    map = userList.stream().collect(Collectors.toMap(User::getAge, user -> user));\n\n    // 需要注意的是,以上写法可能会遇到 key 冲突问题\n    // 这里当 key 冲突时舍弃 id 小的, 取 id 大的\n    map = userList.stream().collect(Collectors.toMap(User::getAge, user -> user, (user1, user2) -> {\n        if (user1.getId() > user2.getId()) {\n            return user1;\n        }\n        return user2;\n    }));\n}\n```\n\n### 过滤\n\n```java\npublic static void example(List<User> userList) {\n    List<User> users;\n\n    users = userList.stream().filter(user -> user.getAge() >= 18)\n            .collect(Collectors.toList());\n    users.forEach(System.out::println);\n\n    // 可以进行展开对 user 做复杂判断\n    users = userList.stream().filter(user -> {\n        if (user.getAge() > 60) {\n            return true;\n        }\n        return false;\n    }).collect(Collectors.toList());\n    users.forEach(System.out::println);\n}\n```\n\n### 去重\n\n```java\npublic static void example(List<User> userList) {\n    // 根据 id 去重\n    List<User> unique = userList.stream().collect(\n            Collectors.collectingAndThen(\n                    Collectors.toCollection(() -> new TreeSet<>(Comparator.comparing(User::getId))), ArrayList::new)\n    );\n}\n```\n\n### 求和\n\n```java\npublic static void example(List<User> userList) {\n    // int 类型\n    int sumAge = userList.stream().mapToInt(User::getAge).sum();\n\n    // 对于高精度数值求和, 可以使用 reduce\n    Optional<BigDecimal> decimalOptional = userList.stream().map(User::getMoney)\n            .reduce(BigDecimal::add);\n\n    if (decimalOptional.isPresent()) {\n        BigDecimal sumMoney = decimalOptional.get();\n        System.out.println(sumMoney);\n    } else {\n        throw new IllegalArgumentException(\"参数错误: money 不能为 null\");\n    }\n\n    // 设置初始值可以避免返回 Optional\n    BigDecimal sumMoney = userList.stream().map(User::getMoney)\n            .reduce(BigDecimal.ZERO, BigDecimal::add);\n    System.out.println(sumMoney);\n\n}\n```\n\n### 查找最大/小值\n\n```java\npublic static void example(List<User> userList) {\n    Optional<User> maxAgeUser = userList.stream().max(Comparator.comparing(User::getAge));\n    maxAgeUser.ifPresent(System.out::println);\n\n    Optional<User> minAgeUser = userList.stream().min(Comparator.comparing(User::getAge));\n    minAgeUser.ifPresent(System.out::println);\n}\n```\n\n### 取交集/并集/差集/去重并集\n\n```java\npublic static void example() {\n    List<Integer> list1 = Arrays.asList(1, 5, 6, 8, 9, 10);\n    List<Integer> list2 = Arrays.asList(2, 5, 6, 7, 9);\n\n    // 一般有filter 操作时，不用并行流parallelStream ,如果用的话可能会导致线程安全问题\n\n    List<Integer> list;\n    // 交集 \t拓展：list2里面如果是对象，则需要提取每个对象的某一属性组成新的list,多个条件则为多个list\n    list = list1.stream().filter(item -> list2.contains(item)).collect(Collectors.toList());\n    // 上面可简写如下\n    list = list1.stream().filter(list2::contains).collect(Collectors.toList());\n    System.out.println(\"---得到交集 intersection---\");\n    list.parallelStream().forEach(System.out::println);\n\n    // 差集 (list1 - list2)\t同上拓展\n    list = list1.stream().filter(item -> !list2.contains(item)).collect(Collectors.toList());\n    System.out.println(\"---得到差集 reduce (list1 - list2)---\");\n    list.parallelStream().forEach(System.out::println);\n}\n```\n","tags":["Java"],"categories":["编程笔记"]},{"title":"注册免费域名","url":"/posts/a8f46ed8.html","content":"\n本文将讲述如何通过 Freenom 注册免费域名\n\n首先打开其注册网址：http://www.freenom.com/zh/index.html\n\n输入一个域名，点击检测可用性，勾选喜欢的域名，\n![](https://cdn.wenzuo.net/assets/202201101200526.png)\n\n按照提示注册即可\n\n<!-- more -->\n\n**注意：在注册过程中，在页面下方会显示你 ip 地址，需要把这个 ip 地址复制出来，打开 http://en.ipip.net/ip.html 粘贴这个 ip 地址，得到“国家 州 城市”信息，这个信息用于填写个人资料，一定要按照这个填写，不然在提交域名订单的时候，会提示无法创建域名**\n\n注册完成后可以在 Services->My Domains 下面看到自己注册的域名，点击 manage domain 即可进入域名管理，按如下图可以自定义 DNS 服务器\n![](https://cdn.wenzuo.net/assets/202201101200172.png)\n","tags":["Tools"],"categories":["实用技能"]},{"title":"git fork 后如何与原仓库同步","url":"/posts/20136f1d.html","content":"\n有时候我们需要 fork 别人的仓库，对代码进行修改，但是在原仓库进行更新时又不想重新 fork，那样会覆盖掉自己已有的修改，这时候我们就需要对原仓库的更新进行 merge，本文将从 fork 开始讲解如何进行操作\n\n<!-- more -->\n\n### fork 仓库\n\n这里以 https://github.com/catch6/hexo-client.git 这个仓库为例，在 github 中点击 fork 按钮对别人的仓库进行 fork\n\n执行 `git clone https://github.com/catch6/hexo-client.git` 命令克隆到本地\n\n执行 `git remote -v` 命令查看远程仓库路径，输出如下：\n\n```bash\norigin\thttps://github.com/catch6/hexo-client.git (fetch)\norigin\thttps://github.com/catch6/hexo-client.git (push)\n```\n\n如果只有上面 2 行，说明你未设置 upstream （中文叫：上游代码库）。一般情况下，设置好一次 upstream 后就无需重复设置。\n\n执行命令 `git remote add upstream https://github.com/gaoyoubo/hexo-client.git` 添加上游，该命令没有任何输出\n\n执行命令 `git remote -v` ，可以看到以下变化\n\n```bash\norigin\thttps://github.com/catch6/hexo-client.git (fetch)\norigin\thttps://github.com/catch6/hexo-client.git (push)\nupstream\thttps://github.com/gaoyoubo/hexo-client.git (fetch)\nupstream\thttps://github.com/gaoyoubo/hexo-client.git (push)\n```\n\n执行命令 `git status` 检查本地是否有未提交的修改。如果有，则把你本地的有效修改，先从本地仓库推送到你的 github 仓库。最后再执行一次 `git status` 检查本地已无未提交的修改。\n\n执行命令 `git fetch upstream` 抓取原仓库的更新\n\n执行命令 `git checkout master` 切换到 master 分支\n\n执行命令 `git merge upstream/master` 合并远程的 master 分支\n\n执行命令 `git push` 把本地仓库向 github 仓库（你 fork 到自己名下的仓库）推送修改\n","tags":["Git"],"categories":["编程笔记"]},{"title":"Nacos 单机与集群部署","url":"/posts/bd59676a.html","content":"\n## Nacos 是什么\n\nNacos 是一个 配置中心+服务注册中心，用于微服务架构的动态配置管理和服务注册发现，目前，Nacos 对 Spring、Spring Boot、Spring Cloud、Dubbo 提供了非常好的支持\n\n<!-- more -->\n\n## 单机部署\n","tags":["Java","SpringCloud","Nacos"],"categories":["编程笔记"]},{"title":"git 同时推送到多个仓库","url":"/posts/516e92b1.html","content":"\n## 查看当前的 remote 列表\n\n```bash\ngit remote -v\n```\n\n<!-- more -->\n\n## 添加 origin\n\n```bash\ngit remote set-url --add origin https://gitee.com/catch6/catch6.git\n```\n\n## 删除 origin\n\n```bash\ngit remote set-url --remove origin https://gitee.com/catch6/catch6.git\n```\n","tags":["Git"],"categories":["编程笔记"]}]